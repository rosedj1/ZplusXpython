{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "my_root_env",
   "display_name": "my_root_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer for Elisa's 3P1F and 2P2F event lists and for CJLST NTuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute `voms-proxy-init` in the shell before starting this JupyNB.\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "# import ROOT as rt\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "top_dir = \"/blue/avery/rosedj1/\"\n",
    "# sys.path.append(top_dir)\n",
    "\n",
    "# top_dir = \"/afs/cern.ch/work/d/drosenzw/zplusx/\"\n",
    "_ = [sys.path.append(os.path.join(top_dir, package)) for package in (\"HiggsMassMeasurement\", \"ZplusXpython\")]\n",
    "# from Utils_Python.Utils_Files import check_overwrite\n",
    "from sidequests.data.cjlst_fw import CjlstFlag\n",
    "from Utils_Python.Commands import shell_cmd\n",
    "from Utils_Python.Utils_Files import save_to_json, open_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_matteo_data2018 = \"/eos/cms/store/group/phys_higgs/cmshzz4l/cjlst/RunIILegacy/200430_LegacyRun2/Data_2018/AllData/ZZ4lAnalysis.root\"\n",
    "t_matteo_up = uproot.open(f\"root://eoscms.cern.ch/{infile_matteo_data2018}:CRZLLTree/candTree\", timeout=180)\n",
    "\n",
    "runnum_arr = t_matteo_up[\"RunNumber\"].array(library=\"np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tree_info_to_txt(infile, outtxt, keep_2P2F=True, keep_3P1F=True):\n",
    "    \"\"\"\n",
    "    Write info from TFile `infile` from TTree 'passedEvents' to `outtxt`.\n",
    "\n",
    "    Info which gets written:\n",
    "    Run : LumiSect : Event\n",
    "    \"\"\"\n",
    "    tfile = rt.TFile.Open(infile)\n",
    "    tree = tfile.Get(\"passedEvents\")\n",
    "\n",
    "    with open(outtxt, \"w\") as f:\n",
    "        f.write(\"# Run : LumiSect : Event\\n\")\n",
    "        for evt in tree:\n",
    "            keep_evt = True if (keep_2P2F and evt.is2P2F) or (keep_3P1F and evt.is3P1F) else False\n",
    "            if keep_evt:\n",
    "                f.write(f\"{evt.Run} : {evt.LumiSect} : {evt.Event}\\n\")\n",
    "    print(f\"TTree info written to:\\n{outtxt}\")\n",
    " \n",
    "def get_list_of_lines(evt_ls_txt):\n",
    "    \"\"\"\n",
    "    Return a list of the lines from `evt_ls_txt`.\n",
    "    The lines must start with a digit.\n",
    "    Trailing newlines ('\\\\n') are stripped.\n",
    "    \"\"\"\n",
    "    with open(evt_ls_txt, \"r\") as f:\n",
    "        return [line.rstrip('\\n') for line in f.readlines() if line[0].isdigit()]\n",
    "\n",
    "def get_list_of_tuples(evt_ls):\n",
    "    \"\"\"\n",
    "    Return a list of 3-tuples from a list of strings `evt_ls`:\n",
    "\n",
    "    [\n",
    "        (Run1, LumiSect1, Event1),\n",
    "        (Run2, LumiSect2, Event2),\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    new_evt_ls = []\n",
    "    for line in evt_ls:\n",
    "        tup = tuple([int(num) for num in line.split(\":\")[:3]])\n",
    "        new_evt_ls.append(tup)\n",
    "    return new_evt_ls\n",
    "\n",
    "def print_evt_info_bbf(tree):\n",
    "    print(f\"tree.passedFullSelection: {tree.passedFullSelection}\")\n",
    "    print(f\"tree.passedZXCRSelection: {tree.passedZXCRSelection}\")\n",
    "    print(f\"tree.nZXCRFailedLeptons: {tree.nZXCRFailedLeptons}\")\n",
    "    print(f\"tree.lep_Hindex: {list(tree.lep_Hindex)}\")\n",
    "    print(f\"tree.lepFSR_pt: {list(tree.lepFSR_pt)}\")\n",
    "    print(f\"tree.lep_RelIso: {list(tree.lep_RelIso)}\")\n",
    "    print(f\"tree.lep_id: {list(tree.lep_id)}\")\n",
    "    print(f\"tree.lep_tightId: {list(tree.lep_tightId)}\")\n",
    "    print(\"#--- PRINT MORE Z AND H INFO HERE. ---#\")\n",
    "\n",
    "def print_evt_info_cjlst(tree):\n",
    "    print(f\"tree.LepPt: {list(tree.LepPt)}\")\n",
    "    print(f\"tree.LepLepId: {list(tree.LepLepId)}\")\n",
    "    print(f\"tree.LepisID (tight lep): {list(np.array(tree.LepisID, dtype=bool))}\")\n",
    "    print(f\"tree.LepisID (tight lep): {list(np.array(tree.LepisID, dtype=bool))}\")\n",
    "    print(f\"tree.CRflag: {tree.CRflag} -> {CjlstFlag(tree.CRflag).name}\")\n",
    "    print(f\"tree.Z1Mass: {tree.Z1Mass}\")\n",
    "    print(f\"tree.Z2Mass: {tree.Z2Mass}\")\n",
    "    print(f\"tree.ZZMass: {tree.ZZMass}\")\n",
    "    print()\n",
    "\n",
    "def analyze_single_evt(tree, run, lumi, event, fw=\"bbf\", which=\"all\", evt_start=0, print_every=10000):\n",
    "    \"\"\"Print out event info (`run`:`lumi`:`event`) found in `tree`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fw : str\n",
    "        Which framework to use: \"bbf\", \"cjlst\"\n",
    "    which : str\n",
    "        Which instance of the event you want to select.\n",
    "        Options: \"first\", anything else prints all such events.\n",
    "    evt_start : int\n",
    "    \"\"\"\n",
    "    print(f\"Searching for event ID {run}:{lumi}:{event} in {fw.upper()} framework\")\n",
    "\n",
    "    n_tot = tree.GetEntries()\n",
    "    for evt_num in range(evt_start, n_tot):\n",
    "        tree.GetEntry(evt_num)\n",
    "        if (evt_num % print_every) == 0:\n",
    "            print(f\"Event {evt_num}/{n_tot}\")\n",
    "\n",
    "        if fw in \"bbf\":\n",
    "            if tree.Run != run:\n",
    "                continue\n",
    "            if tree.LumiSect != lumi:\n",
    "                continue\n",
    "            if tree.Event != event:\n",
    "                continue\n",
    "            if not tree.passedZXCRSelection:\n",
    "                print(f\"[WARNING] Event has passedZXCRSelection == 0.\")\n",
    "            print(f\"Event {run}:{lumi}:{event} found. Index: {evt_num}\")\n",
    "            print_evt_info_bbf(tree)\n",
    "\n",
    "        elif fw in \"cjlst\":\n",
    "            if tree.RunNumber != run:\n",
    "                continue\n",
    "            if tree.LumiNumber != lumi:\n",
    "                continue\n",
    "            if tree.EventNumber != event:\n",
    "                continue\n",
    "            print(f\"Event {run}:{lumi}:{event} found. Index: {evt_num}\")\n",
    "            print_evt_info_cjlst(tree)\n",
    "\n",
    "        if \"first\" in which:\n",
    "            break\n",
    "    print(\"Done.\")\n",
    "\n",
    "def get_control_region(evt):\n",
    "    \"\"\"Return str of control region based on `lep_Hindex` and `lep_tightId`.\n",
    "\n",
    "    Only works for BBF root files.\n",
    "    \"\"\"\n",
    "    l_Hindex_ls = list(evt.lep_Hindex)\n",
    "    assert -1 not in l_Hindex_ls\n",
    "    l_tightId_arr = np.array(evt.lep_tightId)[l_Hindex_ls]\n",
    "\n",
    "    # 3P1F is defined as 3 leptons passing tight and ISO criteria:\n",
    "    l_RelIsoNoFSR_arr = np.array(evt.lep_RelIsoNoFSR)[l_Hindex_ls]\n",
    "    # muons_arr = \n",
    "    # l_RelIsoNoFSR_arr\n",
    "    s = l_tightId_arr.sum()\n",
    "\n",
    "    if s == 4:\n",
    "        return \"SR\"\n",
    "    elif s == 3:\n",
    "        return \"3P1F\"\n",
    "    elif s == 2:\n",
    "        return \"2P2F\"\n",
    "    else:\n",
    "        return f\"[WARNING] Could not assign number of tight leps ({s}) to a CR!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileComparer:\n",
    "\n",
    "    def __init__(self, txt_file1, txt_file2, control_reg=\"\", verbose=False):\n",
    "        \"\"\"\n",
    "        Feed in two txt files to be compared.\n",
    "\n",
    "        NOTE:\n",
    "        - Each txt file is converted to a list of 3-tuples and stored.\n",
    "        - Only lines which begin with a digit are read and stored.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        control_reg : str\n",
    "            Used for printing and writing files.\n",
    "        \"\"\"\n",
    "        self.file1 = txt_file1\n",
    "        self.file2 = txt_file2\n",
    "        self.cr = control_reg\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.check_cr(txt_file1, txt_file2)\n",
    "        if control_reg in \"\":\n",
    "            self.cr = \"all\"\n",
    "        self.ls_of_tup_file1_nodup = None\n",
    "        self.ls_of_tup_file2_nodup = None\n",
    "\n",
    "        # Check for duplicates.\n",
    "        self.ls_of_tup_file1 = get_list_of_tuples(get_list_of_lines(txt_file1))\n",
    "        if self.check_for_dups(txt_file1, self.ls_of_tup_file1):\n",
    "            # Remove duplicates by turning to a set and then back to list.\n",
    "            self.ls_of_tup_file1_nodup = list(set(self.ls_of_tup_file1))\n",
    "        else:\n",
    "            self.ls_of_tup_file1_nodup = self.ls_of_tup_file1\n",
    "\n",
    "        self.ls_of_tup_file2 = get_list_of_tuples(get_list_of_lines(txt_file2))\n",
    "        if self.check_for_dups(txt_file2, self.ls_of_tup_file2):\n",
    "            self.ls_of_tup_file2_nodup = list(set(self.ls_of_tup_file2))\n",
    "        else:\n",
    "            self.ls_of_tup_file2_nodup = self.ls_of_tup_file2\n",
    "\n",
    "        self.compare_files()\n",
    "\n",
    "    def check_for_dups(self, txt_file, ls_of_tup):\n",
    "        \"\"\"Return True and print info if duplicates within a file are found.\"\"\"\n",
    "        len_ls = len(ls_of_tup)\n",
    "        len_set = len(set(ls_of_tup))\n",
    "        if len_ls != len_set:\n",
    "            n_dups = len_ls - len_set\n",
    "            print(f\"[WARNING] Duplicates ({n_dups}) found in file: {txt_file}\")\n",
    "            print(f\"[WARNING] len(ls)={len_ls} != len(set)={len_set}\")\n",
    "            if self.verbose:\n",
    "                # There's some counting error here...\n",
    "                # I know there are 120 duplicates, but counter only finds 118.\n",
    "                counter = Counter(ls_of_tup)\n",
    "                print(f\"Printing duplicates in file:\\n{txt_file}\")\n",
    "                dup_key_ls = [k for k,v in counter.items() if v > 1]\n",
    "                # pprint(dup_key_ls)\n",
    "                # assert n_dups == len(dup_key_ls)\n",
    "                pprint(dup_key_ls)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def check_cr(self, path1, path2):\n",
    "        \"\"\"Make sure that the control region is the one requested.\"\"\"\n",
    "        cr_low = self.cr.lower()\n",
    "        assert cr_low in (\"2p2f\", \"3p1f\", \"\")\n",
    "        # Make sure that the two files have the requested CR.\n",
    "        msg = f\"The `control_reg` ({self.cr}) not found in names of txt files.\"\n",
    "        assert all(cr_low in f.lower() for f in (path1, path2)), msg\n",
    "\n",
    "    def compare_files(self):\n",
    "        \"\"\"Store unique and common info about files. Called when instantiated.\"\"\"\n",
    "        self.set_common_to_both = set(self.ls_of_tup_file1_nodup) & set(self.ls_of_tup_file2_nodup)\n",
    "        self.set_unique_to_file1 = set(self.ls_of_tup_file1_nodup) - set(self.ls_of_tup_file2_nodup)\n",
    "        self.set_unique_to_file2 = set(self.ls_of_tup_file2_nodup) - set(self.ls_of_tup_file1_nodup)\n",
    "\n",
    "    def print_results(self, whose=\"all\", show_n_evts=25, save_to_file=None):\n",
    "        \"\"\"Print info describing differences between two files.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        whose : str\n",
    "            \"file1\", \"file2\", \"all\"\n",
    "        \"\"\"\n",
    "        print(f\"Comparing {self.cr.upper()}:\")\n",
    "        print(f\"file1: {self.file1}\")\n",
    "        print(f\"file2: {self.file2}\")\n",
    "\n",
    "        print(f\"{'n_evts total file1 (no dup): ':<25}{len(self.ls_of_tup_file1_nodup)}\")\n",
    "        print(f\"{'n_evts total file2 (no dup): ':<25}{len(self.ls_of_tup_file2_nodup)}\")\n",
    "        print(f\"{'n_evts in common: ':<25}{len(self.set_common_to_both)}\")\n",
    "        print(f\"{'n_evts unique to file1: ':<25}{len(self.set_unique_to_file1)}\")\n",
    "        print(f\"{'n_evts unique to file2: ':<25}{len(self.set_unique_to_file2)}\")\n",
    "\n",
    "        header = \"#-- Run -- LumiSect -- Event --#\"\n",
    "        if show_n_evts == -1:\n",
    "            show_n_evts = None\n",
    "        if whose in (\"file1\", \"all\"):\n",
    "            print(f\"  file1's unique events:\")\n",
    "            print(header)\n",
    "            pprint(list(self.set_unique_to_file1)[:show_n_evts])\n",
    "            print()\n",
    "        if whose in (\"file2\", \"all\"):\n",
    "            print(f\"  file2's unique events:\")\n",
    "            print(header)\n",
    "            pprint(list(self.set_unique_to_file2)[:show_n_evts])\n",
    "            print()\n",
    "\n",
    "    def save_events_to_txt(self, kind, outtxt, no_dup=True, overwrite=False):\n",
    "        \"\"\"\n",
    "        Write the events to `outtxt` in the format:\n",
    "\n",
    "        Run : LumiSect : Event\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        kind : str\n",
    "            Choose which events to write to `outtxt`.\n",
    "            \"file1\", \"file2\", \"common\", \"file1_unique\", \"file2_unique\"\n",
    "        \"\"\"\n",
    "        check_overwrite(outtxt, overwrite=overwrite)\n",
    "        assert kind in (\"file1\", \"file2\", \"common\", \"file1_unique\", \"file2_unique\")\n",
    "\n",
    "        if kind in \"file1\":\n",
    "            iter_ls_of_tup = self.ls_of_tup_file1_nodup if no_dup else self.ls_of_tup_file1\n",
    "        elif kind in \"file2\":\n",
    "            iter_ls_of_tup = self.ls_of_tup_file2_nodup if no_dup else self.ls_of_tup_file2\n",
    "        elif kind in \"common\":\n",
    "            iter_ls_of_tup = self.set_common_to_both\n",
    "        elif kind in \"file1_unique\":\n",
    "            iter_ls_of_tup = self.set_unique_to_file1\n",
    "        elif kind in \"file2_unique\":\n",
    "            iter_ls_of_tup = self.set_unique_to_file2\n",
    "\n",
    "        with open(outtxt, \"w\") as f:\n",
    "            f.write(\"# Run : LumiSect : Event\\n\")\n",
    "            for tup in iter_ls_of_tup:\n",
    "                f.write(f\"{tup[0]} : {tup[1]} : {tup[2]}\\n\")\n",
    "            print(f\"Wrote '{self.cr} {kind}' events to file:\\n{outtxt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile_jake_tree = \"/blue/avery/rosedj1/ZplusXpython/data/ZLL_CR_FRapplied/Data_2018_NoDuplicates_RunEventLumi.root\"\n",
    "infile_jake_tree = \"/blue/avery/rosedj1/ZplusXpython/data/ZLL_CR_FRapplied/new_data2018/cr_ZLL.root\"\n",
    "# ^Contains all the passedZXCRSelection events as in:\n",
    "# /fullstats/ZL_ZLL_4P_CR/noduplicates/Data2018_NoDuplicates.root\n",
    "\n",
    "#####################\n",
    "#--- CJLST files ---#\n",
    "#####################\n",
    "infile_elisa       = \"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/CRLLos_listOfEvents.txt\"\n",
    "infile_elisa_2p2f  = \"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/CRLLos_2P2F_listOfEvents.txt\"\n",
    "infile_elisa_3p1f  = \"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/CRLLos_3P1F_listOfEvents.txt\"\n",
    "infile_matteo_data2018 = \"/eos/cms/store/group/phys_higgs/cmshzz4l/cjlst/RunIILegacy/200430_LegacyRun2/Data_2018/AllData/ZZ4lAnalysis.root\"\n",
    "infile_cjlst_sr = \"/blue/avery/rosedj1/ZplusXpython/sidequests/data/2018_CJLST_finalSelectedEvents_SR.txt\"\n",
    "\n",
    "elisa_3p1f_unique_evtid_dct_json = \"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/elisa_3p1f_unique_evtID_CR_dct.json\"\n",
    "\n",
    "\n",
    "outdir = \"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/jakes_new2018data/\"\n",
    "\n",
    "infile_jake      = os.path.join(outdir, \"CRLLos_listOfEvents_jake.txt\")\n",
    "infile_jake_2p2f = os.path.join(outdir, \"CRLLos_listOfEvents_jake_2P2F.txt\")\n",
    "infile_jake_3p1f = os.path.join(outdir, \"CRLLos_listOfEvents_jake_3P1F.txt\")\n",
    "infile_elisa_unique_353 = \"/blue/avery/rosedj1/ZplusXpython/sidequests/rootfiles/elisa_unique_353events.root\"\n",
    "\n",
    "outfile_elisa_2p2f_unique  = os.path.join(outdir, \"CRLLos_2P2F_listOfEvents_unique.txt\")\n",
    "outfile_elisa_3p1f_unique  = os.path.join(outdir, \"CRLLos_3P1F_listOfEvents_unique.txt\")\n",
    "outfile_jake_2p2f_unique = os.path.join(outdir, \"CRLLos_listOfEvents_jake_2P2F_unique.txt\")\n",
    "outfile_jake_3p1f_unique = os.path.join(outdir, \"CRLLos_listOfEvents_jake_3P1F_unique.txt\")\n",
    "outfile_LLR_data2018 = \"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/\"\n",
    "\n",
    "outfile_2p2f_common = os.path.join(outdir, \"CRLLos_listOfEvents_2P2F_common.txt\")\n",
    "outfile_3p1f_common = os.path.join(outdir, \"CRLLos_listOfEvents_3P1F_common.txt\")\n",
    "# write_tree_info_to_txt(infile_jake_tree, infile_jake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make txt files of events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tree_info_to_txt(infile_jake_tree, infile_jake_2p2f, keep_2P2F=True, keep_3P1F=False)\n",
    "write_tree_info_to_txt(infile_jake_tree, infile_jake_3p1f, keep_2P2F=False, keep_3P1F=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_elisa_2p2fvs3p1f = FileComparer(infile_elisa_2p2f, infile_elisa_3p1f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fc_jakevselisa_3p1f = FileComparer(infile_jake_3p1f, infile_elisa_3p1f, control_reg=\"3p1f\", verbose=True)\n",
    "fc_jakevselisa_2p2f = FileComparer(infile_jake_2p2f, infile_elisa_2p2f, control_reg=\"2p2f\", verbose=True)\n",
    "fc_jakevselisa_all  = FileComparer(infile_jake, infile_elisa, control_reg=\"\", verbose=True)\n",
    "\n",
    "# fc_jakevselisa_3p1f.print_results(whose=\"file1\", show_n_evts=5)\n",
    "# fc_jakevselisa_3p1f.print_results(whose=\"file2\", show_n_evts=5)\n",
    "# fc_jakevselisa_2p2f.print_results(whose=\"file1\", show_n_evts=5)\n",
    "# fc_jakevselisa_2p2f.print_results(whose=\"file2\", show_n_evts=5)\n",
    "# # fc_jakevselisa_all.print_results(whose=\"all\", show_n_evts=10)\n",
    "\n",
    "# # Write the events to txt.\n",
    "# overwrite = 0\n",
    "# fc_jakevselisa_3p1f.save_events_to_txt(kind=\"file1_unique\", outtxt=outfile_jake_3p1f_unique, no_dup=True, overwrite=overwrite)\n",
    "# fc_jakevselisa_3p1f.save_events_to_txt(kind=\"file2_unique\", outtxt=outfile_elisa_3p1f_unique, no_dup=True, overwrite=overwrite)\n",
    "# fc_jakevselisa_3p1f.save_events_to_txt(kind=\"common\", outtxt=outfile_3p1f_common, no_dup=True, overwrite=overwrite)\n",
    "\n",
    "# fc_jakevselisa_2p2f.save_events_to_txt(kind=\"file1_unique\", outtxt=outfile_jake_2p2f_unique, no_dup=True, overwrite=overwrite)\n",
    "# fc_jakevselisa_2p2f.save_events_to_txt(kind=\"file2_unique\", outtxt=outfile_elisa_2p2f_unique, no_dup=True, overwrite=overwrite)\n",
    "# fc_jakevselisa_2p2f.save_events_to_txt(kind=\"common\", outtxt=outfile_2p2f_common, no_dup=True, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fc_jakevselisa_all.ls_of_tup_file2) - len(fc_jakevselisa_all.ls_of_tup_file2_nodup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a manual counter.\n",
    "# Print out events which appear more than once in fc_jakevselisa_all.ls_of_tup_file2.\n",
    "for f in fc_jakevselisa_all.ls_of_tup_file2:\n",
    "    ct = 0\n",
    "    if f in fc_jakevselisa_all.ls_of_tup_file2_nodup:\n",
    "        if ct == 5: break\n",
    "        print(f)\n",
    "# Identify the 2 events from 120 which didn't appear in 118.\n",
    "# Why did counter not find them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLR Group's (diff. xs) RedBkg Files\n",
    "\n",
    "Vukasin pointed me to their root files:\n",
    "\n",
    "- `/afs/cern.ch/user/v/vmilosev/public/forJake/new_ZX_LLR/AllData*`\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_llr_2018 = \"/blue/avery/rosedj1/ZplusXpython/sidequests/data/LLR_redbkg/AllData_ZX_redTree_2018.root\"\n",
    "\n",
    "f_llr = TFile(infile_llr_2018)\n",
    "t_llr = f_llr.Get(\"SelectedTree\")\n",
    "\n",
    "odd_event = (315488, 152, 135937874, )\n",
    "\n",
    "n_tot_evts = t_llr.GetEntries()\n",
    "for evt_num, evt in enumerate(t_llr):\n",
    "    if (evt_num % 500) == 0:\n",
    "        print(f\"Checking event #{evt_num}/{n_tot_evts}\")\n",
    "    if evt.RunNumber != odd_event[0]:\n",
    "        continue\n",
    "    if evt.LumiNumber != odd_event[1]:\n",
    "        continue\n",
    "    if evt.EventNumber != odd_event[2]:\n",
    "        continue\n",
    "    print(f\"Event found ({evt.RunNumber}:{evt.LumiNumber}:{evt.EventNumber}) at index {evt_num}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(t.GetListOfBranches())\n",
    "\n",
    "t.Scan(\"htxs_stage1_red_cat:htxs_stage1_red_catName:htxs_stage1_red_prod_cat:htxs_stage1_red_prod_catName\")\n",
    "\n",
    "#--- Counting instances of htxs_stage1 ---#\n",
    "# htxs_stage1_red_catName_ls = [str(evt.htxs_stage1_red_catName) for evt in t if evt.htxs_stage1_red_catName == 'ZX']\n",
    "# count_ZX_str = Counter(htxs_stage1_red_catName_ls)\n",
    "htxs_stage1_red_cat_ls = [str(evt.htxs_stage1_red_cat) for evt in t if evt.htxs_stage1_red_cat == -2]\n",
    "count_ZX_cat = Counter(htxs_stage1_red_cat_ls)\n",
    "# dup_key_ls = [k for k,v in counter.items() if v > 1]\n",
    "print(count_ZX_cat)\n",
    "\n",
    "t.GetEntries()  # 12331\n",
    "\n",
    "#--- Tried to match any of Elisa's ZLL events to diff. xs group's events.\n",
    "#--- None matched.\n",
    "elisa_evtid_2p2f_tup = get_list_of_tuples(get_list_of_lines(infile_elisa_2p2f))\n",
    "n_tot_tup = len(elisa_evtid_2p2f_tup)\n",
    "start_at = 1000\n",
    "for num_tup, tup in enumerate(elisa_evtid_2p2f_tup[start_at:], start_at):\n",
    "    if (num_tup % 1000) == 0:\n",
    "        print(f\"Checking tuple #{num_tup}/{n_tot_tup}\")\n",
    "    for evt_num, evt in enumerate(t):\n",
    "        if evt.RunNumber != elisa_evtid_2p2f_tup_example[0]:\n",
    "            continue\n",
    "        if evt.LumiNumber != elisa_evtid_2p2f_tup_example[1]:\n",
    "            continue\n",
    "        if evt.EventNumber != elisa_evtid_2p2f_tup_example[2]:\n",
    "            continue\n",
    "        print(f\"Event {evt_num}, {evt.RunNumber}:{evt.LumiNumber}:{evt.EventNumber}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "These are Diff. XS Group's SR samples.\n",
    "They do not contain RedBkg info.\n",
    "\n",
    "### So What Next?\n",
    "\n",
    "Matteo gave me a CJLST 2018 Data NTuple to look at.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify duplicate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of 3P1F, 2P2F, and SS events in CJLST NTuples:\n",
    "for c in CjlstFlag:\n",
    "    conreg = c.name\n",
    "    n = t_matteo.GetEntries(f\"CRflag == {c}\")\n",
    "    print(f\"Number of {conreg} entries: {n}\")\n",
    "# Output:\n",
    "# Number of CR3P1F entries: 4806  (after removing duplicate -> 4805)\n",
    "# Number of CR2P2F entries: 46067 (after removing duplicate -> 46066)\n",
    "# Number of CRLLss entries: 50144\n",
    "# I believe there is one duplicate in 3P1F and 2P2F:\n",
    "# 315512 : 947 : 703286863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building CJLST event analyzer.\n",
    "dup = (315512, 947, 703286863)\n",
    "ct = 0\n",
    "dup_dict = {}\n",
    "    for evt_num, evt in enumerate(t):\n",
    "        if evt.RunNumber != :\n",
    "            continue\n",
    "        if evt.LumiNumber != :\n",
    "            continue\n",
    "        if evt.EventNumber != :\n",
    "            continue\n",
    "    ct += 1\n",
    "    dup_dict[evt_num] = (evt.RunNumber, evt.LumiNumber, evt.EventNumber, evt.Z1Mass, evt.Z2Mass, evt.ZZMass,)\n",
    "    if ct > 1:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guinea_pig_tup = (315512, 947, 703286863, )\n",
    "for evt_num, evt in enumerate(t_jake_2018data):\n",
    "    if evt.Run != guinea_pig_tup[0]:\n",
    "        continue\n",
    "    if evt.LumiSect != guinea_pig_tup[1]:\n",
    "        continue\n",
    "    if evt.Event != guinea_pig_tup[2]:\n",
    "        continue\n",
    "    print(f\"Event number {evt_num}.\")\n",
    "    print(f\"lep_pt: {list(evt.lep_pt)}\")\n",
    "    print(f\"lep_FSRpt: {list(evt.lep_FSRpt)}\")\n",
    "    break\n",
    "\n",
    "\n",
    "# t_jake_2018data.GetEntry(660)\n",
    "print(f\"t_jake_2018data.lep_Hindex: {list(t_jake_2018data.lep_Hindex)}\")\n",
    "print(f\"t_jake_2018data.lepFSR_pt: {list(t_jake_2018data.lepFSR_pt)}\")\n",
    "print(f\"t_jake_2018data.lep_RelIso: {list(t_jake_2018data.lep_RelIso)}\")\n",
    "print(f\"t_jake_2018data.lep_id: {list(t_jake_2018data.lep_id)}\")\n",
    "print(f\"t_jake_2018data.lep_tightId: {list(t_jake_2018data.lep_tightId)}\")\n",
    "# print(f\"t_jake_2018data.lep_tightId: {t_jake_2018data.lep_tightId}\")\n",
    "# print(f\"t_jake_2018data.lep_RelIsoNoFSR: {t_jake_2018data.RelIsoNoFSR}\")\n",
    "\n",
    "# print(f\"t_jake_2018data.lep_id: {t_jake_2018data.lep_id}\")\n",
    "\n",
    "t_jake_2018data.passedZXCRSelection\n",
    "print(t_jake_2018data.Run)\n",
    "print(t_jake_2018data.LumiSect)\n",
    "print(t_jake_2018data.Event)\n",
    "\n",
    "# elisa_unique_event_3p1f_325159_181_259586791.root\n",
    "unique_3p1f_evt = (321973, 1133, 1973286739,)\n",
    "for evt_num, evt in enumerate(t_jake_2018data):\n",
    "    if evt.Run != unique_3p1f_evt[0]:\n",
    "        continue\n",
    "    if evt.LumiSect != unique_3p1f_evt[1]:\n",
    "        continue\n",
    "    if evt.Event != unique_3p1f_evt[2]:\n",
    "        continue\n",
    "    print(f\"Event number {evt_num}.\")\n",
    "    print(f\"lep_pt: {list(evt.lep_pt)}\")\n",
    "    print(f\"lep_FSRpt: {list(evt.lep_FSRpt)}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import TFile\n",
    "f_matteo = TFile.Open(f\"root://eoscms.cern.ch/{infile_matteo_data2018}\")\n",
    "t_matteo = f_matteo.Get(\"CRZLLTree/candTree\")\n",
    "print(f\"File opened:\\n{infile_matteo_data2018}\")\n",
    "\n",
    "f_jake = TFile.Open(infile_jake_tree)\n",
    "t_jake = f_jake.Get(\"passedEvents\")\n",
    "\n",
    "f_elisa_353 = TFile(infile_elisa_unique_353)\n",
    "t_elisa_353 = f_elisa_353.Get(\"Ana/passedEvents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a `dict` (all CJLST eventIDs : CRs) and then look for Elisa's unique events.\n",
    "\n",
    "- All of Elisa's events were (of course) found in the CJLST NTuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tot_cjlst = t_matteo.GetEntries()\n",
    "cjlst_evtid_dct = {}\n",
    "for evt_num, evt in enumerate(t_matteo):\n",
    "    if (evt_num % 5000) == 0:\n",
    "        print(f\"CJLST TTree at entry: {evt_num}/{n_tot_cjlst}\")\n",
    "    key = f\"{evt.RunNumber} : {evt.LumiNumber} : {evt.EventNumber}\"\n",
    "    this_single_cr_ls = [CjlstFlag(evt.CRflag).name]\n",
    "    if key not in cjlst_evtid_dct.keys():\n",
    "        cjlst_evtid_dct[key] = this_single_cr_ls\n",
    "    else:\n",
    "        # Event with this Run:Lumi:Event has already been stored.\n",
    "        # This entry contains a new CR (by combining different leptons).\n",
    "        cjlst_evtid_dct[key].extend(this_single_cr_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "outfile = \"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/cjlst_evtID_CR_dct.json\"\n",
    "\n",
    "with open(outfile, 'w') as f:\n",
    "    json.dump(cjlst_evtid_dct, f, indent=4, sort_keys=False)\n",
    "print(f\"[INFO] JSON file written:\\n{outfile}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cjlst_evtid_dct = open_json(\"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/cjlst_evtID_CR_dct.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dict (Elisa's eventIDs : CRs).\n",
    "elisa_3p1f_unique_ls_tup = get_list_of_tuples(get_list_of_lines(outfile_elisa_3p1f_unique))\n",
    "\n",
    "n_tot_uniq = len(elisa_3p1f_unique_ls_tup)\n",
    "n_tot_cjlst = t_matteo.GetEntries()\n",
    "elisa_3p1f_unique_evtid_dct = {}\n",
    "\n",
    "for unique_evt_num, evt_id in enumerate(elisa_3p1f_unique_ls_tup, 1):\n",
    "    if (unique_evt_num % 100) == 0:\n",
    "        print(f\"Searching for Elisa's unique event {unique_evt_num}/{n_tot_uniq}: {evt_id}\")\n",
    "    elisa_key = f\"{evt_id[0]} : {evt_id[1]} : {evt_id[2]}\"\n",
    "    elisa_3p1f_unique_evtid_dct[elisa_key] = cjlst_evtid_dct[elisa_key]\n",
    "\n",
    "save_to_json(elisa_3p1f_unique_evtid_dct, elisa_3p1f_unique_evtid_dct_json, overwrite=False, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now study the properties of CJLST's unique 3P1F events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter(elisa_3p1f_unique_evtid_dct.keys())\n",
    "# list(elisa_3p1f_unique_evtid_dct.values())[:15]\n",
    "ct = 0\n",
    "for uniq_evtID, cr in elisa_3p1f_unique_evtid_dct.items():\n",
    "    # if (\"CR3P1F\" in cr) and (len(cr) == 1):\n",
    "    if \"CR2P2F\" in cr:\n",
    "        print(f\"eventID = {uniq_evtID}, CR = {cr}\")\n",
    "        ct += 1\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do any of the unique events also belong to SR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Make a dict(CJLST's SR eventID : CR) events. ---#\n",
    "# cjlst_sr_ls_tup = get_list_of_tuples(get_list_of_lines(infile_cjlst_sr))\n",
    "# cjlst_evtid_sr_dct = {k:['SR'] for k in cjlst_sr_ls_tup}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elisa_3p1f_unique_evtid_dct = open_json(elisa_3p1f_unique_evtid_dct_json)\n",
    "elisa_3p1fonly_unique_ls = [k for k,v in elisa_3p1f_unique_evtid_dct.items() if len(v) == 1 and 'CR3P1F' in v]\n",
    "\n",
    "# set(cjlst_evtid_sr_dct.keys()) & set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['321973 : 1133 : 1973286739',\n",
       " '321834 : 84 : 126135620',\n",
       " '320821 : 118 : 130885195',\n",
       " '316766 : 179 : 208365005']"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# A few of Elisa's unique 3P1F events that belong to ONLY 3P1F:\n",
    "elisa_3p1fonly_unique_ls[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Searching for event ID 321973:1133:1973286739 in BBF framework\nEvent 0/353\nDone.\n"
     ]
    }
   ],
   "source": [
    "# t_elisa_353 = BBF TTree, edmPickEvents on all of Elisa's unique 3P1F events.\n",
    "analyze_single_evt(t_elisa_353, 321973, 1133, 1973286739, fw=\"bbf\", which=\"all\", evt_start=0, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_single_evt(t_elisa_353, run, lumi, event, fw=\"bbf\", which=\"all\", evt_start=0, print_every=1000)\n",
    "analyze_single_evt(t_elisa_353, 321973, 1133, 1973286739, fw=\"cjlst\", which=\"all\", evt_start=0, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(321973, 1133, 1973286739),\n",
       " (321834, 84, 126135620),\n",
       " (316766, 179, 208365005),\n",
       " (320821, 118, 130885195)]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "elisa_3p1fonly_unique_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['324245 : 1579 : 2934965254',\n",
       " '321414 : 603 : 1034233936',\n",
       " '321990 : 164 : 299221432']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "set(elisa_3p1fonly_unique_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_elisa_353_evtls = [(evt.Run, evt.LumiSect, evt.Event, ) for evt in t_elisa_353]\n",
    "set_elisa_353_evt = set(t_elisa_353_evtls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elisa_3p1fonly_unique_set = set()\n",
    "for evtid in elisa_3p1fonly_unique_ls:\n",
    "    str_ls = evtid.split(\":\")\n",
    "    str_ls = [s.rstrip().lstrip() for s in str_ls]\n",
    "    run = int(str_ls[0])\n",
    "    lumi = int(str_ls[1])\n",
    "    event = int(str_ls[2])\n",
    "    elisa_3p1fonly_unique_set.add((run, lumi, event, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(322430, 331, 543297179),\n",
       " (325159, 181, 259586791),\n",
       " (320038, 81, 76284361),\n",
       " (324201, 414, 808176523),\n",
       " (322204, 866, 1544245921)]"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "ntrsct_353evt_and_elisa3p1fonlyunique_ls = list(set_elisa_353_evt & elisa_3p1fonly_unique_set)\n",
    "ntrsct_353evt_and_elisa3p1fonlyunique_ls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "len(ntrsct_353evt_and_elisa3p1fonlyunique_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_single_evt(t_matteo, 322430, 331, 543297179, fw=\"cjlst\", which=\"all\", evt_start=0, print_every=10000)  # event index: 52198\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Searching for event ID 325159:181:259586791 in CJLST framework\n",
      "Event 0/101017\n",
      "Event 10000/101017\n",
      "Event 20000/101017\n",
      "Event 30000/101017\n",
      "Event 40000/101017\n",
      "Event 50000/101017\n",
      "Event 325159:181:259586791 found. Index: 52490\n",
      "tree.LepPt: [14.290181159973145, 63.82860565185547, 72.60548400878906, 8.89677906036377]\n",
      "tree.LepLepId: [-11, 11, -13, 13]\n",
      "tree.LepisID (tight lep): [True, True, True, True]\n",
      "tree.CRflag: 8388608 -> CR3P1F\n",
      "tree.Z1Mass: 66.72291564941406\n",
      "tree.Z2Mass: 82.42644500732422\n",
      "tree.ZZMass: 453.1827697753906\n",
      "\n",
      "Event 60000/101017\n",
      "Event 70000/101017\n",
      "Event 80000/101017\n",
      "Event 90000/101017\n",
      "Event 100000/101017\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "analyze_single_evt(t_matteo, 325159, 181, 259586791, fw=\"cjlst\", which=\"all\", evt_start=0, print_every=10000)  # event index: 52490\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Searching for event ID 322430:331:543297179 in BBF framework\nEvent 0/353\n[WARNING] Event has passedZXCRSelection == 0.\nEvent 322430:331:543297179 found. Index: 279\ntree.passedFullSelection: 0\ntree.passedZXCRSelection: 0\ntree.nZXCRFailedLeptons: 0\ntree.lep_Hindex: [-1, -1, -1, -1]\ntree.lepFSR_pt: [96.67301177978516, 83.3065414428711, 17.891992568969727, 17.53435516357422]\ntree.lep_RelIso: [0.0, 0.0, 2.3615872859954834, 0.2649592459201813]\ntree.lep_id: [13, -11, 11, -13]\ntree.lep_tightId: [1, 1, 0, 1]\n#--- PRINT MORE Z AND H INFO HERE. ---#\nDone.\n"
     ]
    }
   ],
   "source": [
    "analyze_single_evt(t_elisa_353, 322430, 331, 543297179, fw=\"bbf\", which=\"all\", evt_start=0, print_every=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Difference between CJLST and BBF Analyzers:\n",
    "\n",
    "- Elisa has 432 unique 3P1F-only events (`elisa_3p1fonly_unique_ls`).\n",
    "- Of these, I scraped 236 events (`ntrsct_353evt_and_elisa3p1fonlyunique_ls`) and ran the UFHZZAnalyzer on them.\n",
    "\n",
    "Filippo suspects that CJLST does not require the Z1 leptons to be tight.\n",
    "\n",
    "- [ ] Count how many of the 236 events have a Z1 lep which is not \"fully tight\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cr_counts = Counter([tuple(sorted(v)) for v in elisa_3p1f_unique_evtid_dct.values()])\n",
    "# df = pd.DataFrame.from_dict(cr_counts, orient='index')\n",
    "# df.plot(kind='bar', legend=False, figsize=(12,9), grid=True, logy=False, fontsize=20, tick)\n",
    "\n",
    "cr_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tot_uniq = len(elisa_3p1f_unique_ls_tup)\n",
    "n_tot_cjlst = t_matteo.GetEntries()\n",
    "elisa_3p1f_unique_evtid_dct = {}\n",
    "\n",
    "for unique_evt_num, evt_id in enumerate(elisa_3p1f_unique_ls_tup[:1], 1):\n",
    "    if (unique_evt_num % 1) == 0:\n",
    "        print(f\"Searching for Elisa's unique event {unique_evt_num}/{n_tot_uniq}: {evt_id}\")\n",
    "    cr_ls = []\n",
    "    run   = evt_id[0]\n",
    "    lumi  = evt_id[1]\n",
    "    event = evt_id[2]\n",
    "    new_key = f\"{run} : {lumi} : {event}\"\n",
    "    for cjlst_evt_num, cjlst_evt in enumerate(t_matteo):\n",
    "        if (cjlst_evt_num % 10000) == 0:\n",
    "            print(f\"Scanning CJLST TTree for matching entry: {cjlst_evt_num}/{n_tot_cjlst}\")\n",
    "        if (run != cjlst_evt.RunNumber):\n",
    "            continue\n",
    "        if (lumi != cjlst_evt.LumiNumber):\n",
    "            continue\n",
    "        if (event != cjlst_evt.EventNumber):\n",
    "            continue\n",
    "        print(f\"EVENT FOUND! Entry number: {cjlst_evt_num}\")\n",
    "        cr_ls.extend([CjlstFlag(cjlst_evt.CRflag).name])\n",
    "    # cr_ls = [CjlstFlag(evt.CRflag).name for evt in t_matteo if (run == evt.RunNumber) and (lumi == evt.LumiNumber) and (event == evt.EventNumber)]\n",
    "    elisa_3p1f_unique_evtid_dct[new_key] = cr_ls\n",
    "pprint(elisa_3p1f_unique_evtid_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_id_ls_matteo = [(evt.RunNumber, evt.LumiNumber, evt.EventNumber,) for evt in t_matteo]\n",
    "len(evt_id_ls_matteo) - len(set(evt_id_ls_matteo))\n",
    "counter = Counter(evt_id_ls_matteo)\n",
    "# pprint(list(counter.values())[:5])\n",
    "dup_key_ls = [(k, ct) for k,ct in counter.items() if k == (315488, 152, 135937874,)]\n",
    "\n",
    "evt_id_tup = (315488, 152, 135937874, )\n",
    "counter[evt_id_tup]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find how many of CJLST RedBkg events contain exactly 4 leps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "#--- CJLST ---#\n",
    "###############\n",
    "n_tot = t_matteo.GetEntries()\n",
    "redbkg_CRs = [flag.name for flag in CjlstFlag]\n",
    "cr_flag_ls_cjlst = []\n",
    "\n",
    "print(\"Finding all events in CJLST file with 4 leps per event.\")\n",
    "for evt_num, evt in enumerate(t_matteo):\n",
    "    if (evt_num % 10000) == 0:\n",
    "        print(f\"Event {evt_num}/{n_tot}\")\n",
    "    n_reco_ele = evt.NRecoEle\n",
    "    n_reco_mu  = evt.NRecoMu\n",
    "    if (n_reco_ele + n_reco_mu) != 4:\n",
    "        continue\n",
    "    cr_flag_ls_cjlst.extend([evt.CRflag])\n",
    "# Count occurrence of each CR:\n",
    "print(f\"Number of events with 4 leps: {len(cr_flag_ls_cjlst)}\")\n",
    "cr_flag_cntr_cjlst = Counter(cr_flag_ls_cjlst)\n",
    "pprint([(CjlstFlag(k).name, ct) for k, ct in cr_flag_cntr_cjlst.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#--- BBF ---#\n",
    "#############\n",
    "n_tot = t_jake.GetEntries()\n",
    "redbkg_CRs = [flag.name for flag in CjlstFlag]\n",
    "cr_flag_ls_bbf = []\n",
    "evts_to_investigate = []\n",
    "\n",
    "print(\"Finding all events in BBF file with 4 leps per event.\")\n",
    "for evt_num, evt in enumerate(t_jake):\n",
    "    if (evt_num % 5000) == 0:\n",
    "        print(f\"Event {evt_num}/{n_tot}\")\n",
    "    if len(evt.lep_pt) != 4:\n",
    "        continue\n",
    "    cr_flag_ls_bbf.extend([get_control_region(evt)])\n",
    "\n",
    "    if sum(list(evt.lep_tightId)) >= 4:\n",
    "        evts_to_investigate.extend([evt_num])\n",
    "# Count occurrence of each CR:\n",
    "print(f\"Number of events with 4 leps: {len(cr_flag_ls_bbf)}\")\n",
    "cr_flag_cntr_bbf = Counter(cr_flag_ls_bbf)\n",
    "pprint([(k, ct) for k, ct in cr_flag_cntr_bbf.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What the heck? I've found events with `passedZXCRSelection == 1` but with exactly 4 tight leps...\n",
    "\n",
    "#### We must also keep in mind the RelIso!\n",
    "\n",
    "Let's investigate the originally-produced data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_muonEG2018 = \"/cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/MuonEG.root\"\n",
    "f_muonEG2018 = TFile(infile_muonEG2018)\n",
    "t_muonEG2018 = f_muonEG2018.Get(\"Ana/passedEvents\")\n",
    "t_muonEG2018.GetEntries()  # 5228705.\n",
    "t_muonEG2018.GetEntries(\"passedZXCRSelection==1\")  # 8363.\n",
    "t_muonEG2018.GetEntries(\"passedZXCRSelection==1 && Sum$(lep_tightId) == 4 && Length$(lep_pt) == 4\")  # 353.\n",
    "# Comparing per-element of a vector - Filippo suggests: &Lep_pt[0]\n",
    "\n",
    "# weird_tightId_ls = [] \n",
    "# for evt_num, evt in enumerate(t_muonEG2018):\n",
    "#     if () == 0: print(f\"\")\n",
    "#     if not evt.passedZXCRSelection: continue \n",
    "#     tightId_ls = list(evt.lep_tightId) \n",
    "#     if len(tightId_ls) != 4: continue \n",
    "#     if sum(tightId_ls) != 4: continue \n",
    "#     weird_tightId_ls.extend([evt_num]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many tight leptons are there per event?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ROOT import TFile, TCanvas, TPaveText, gStyle, gPad\n",
    "from Utils_ROOT.ROOT_classes import make_TH2F\n",
    "from Utils_ROOT.Printer import CanvasPrinter\n",
    "from Utils_Python.Plot_Styles_ROOT.tdrstyle_official import setTDRStyle, tdrGrid, fixOverlay\n",
    "# =============================================================================\n",
    "def normalize_TH2_per_column(h2):\n",
    "    \"\"\"Return a new TH2F with cells normalized to sum(cols) in which the cell\n",
    "    is found.\n",
    "    \n",
    "    NOTE:\n",
    "    - Doesn't affect under/overflow bins.\n",
    "    - Errors should be handled more properly.\n",
    "    \"\"\"\n",
    "    h2_norm = h2.Clone()\n",
    "    h2_norm.Reset()\n",
    "    # Go column by column and get the integral:\n",
    "    nx_bins = h2.GetNbinsX()\n",
    "    ny_bins = h2.GetNbinsY()\n",
    "    for x_bin in range(1, nx_bins+1):\n",
    "        proj_y = h2.ProjectionY(f\"proj_y_{x_bin}\", x_bin, x_bin)\n",
    "        integ = proj_y.Integral()\n",
    "        del proj_y\n",
    "        if integ == 0:\n",
    "            # Column completely empty.\n",
    "            continue\n",
    "        # Scale each cell in this column by the integral:\n",
    "        y_sum = 0\n",
    "        for y_bin in range(1, ny_bins+1):\n",
    "            glob_bin = h2.GetBin(x_bin, y_bin)\n",
    "            val = h2.GetBinContent(glob_bin)\n",
    "            err = h2.GetBinError(glob_bin)\n",
    "            fill_val = val / float(integ)\n",
    "            fill_val_err = err / float(integ)\n",
    "            h2_norm.SetBinContent(glob_bin, fill_val)\n",
    "            h2_norm.SetBinError(glob_bin, fill_val_err)\n",
    "    return h2_norm\n",
    "\n",
    "def make_pave_with_stats(h2, xmin=0.15, ymin=0.8, xmax=0.4, ymax=0.9):\n",
    "    \"\"\"Return a TPave with simple stats located at (xmin, ymin, xmax, ymax).\"\"\"\n",
    "    pave = TPaveText(xmin, ymin, xmax, ymax, \"NDC\")  # NDC = normalized coord.\n",
    "    pave.SetFillColor(0)\n",
    "    pave.SetFillStyle(1001)  # Solid fill.\n",
    "    pave.SetBorderSize(1) # Use 0 for no border.\n",
    "    pave.SetTextAlign(11)\n",
    "    pave.SetTextSize(0.02)\n",
    "    pave.AddText(f\"Entries: {h2.GetEntries():.3f}\")\n",
    "    pave.AddText(f\"Integral: {h2.Integral():.3f}\")\n",
    "    # pave.Draw(\"same\")\n",
    "    return pave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_filippo_data2018 = TFile.Open(\"/cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/Data_2018_03Nov.root\")\n",
    "t_filippo_data2018 = f_filippo_data2018.Get(\"passedEvents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Event 0/8094112\n",
      "Event 500000/8094112\n",
      "Event 1000000/8094112\n",
      "Event 1500000/8094112\n",
      "Event 2000000/8094112\n",
      "Event 2500000/8094112\n",
      "Event 3000000/8094112\n",
      "Event 3500000/8094112\n",
      "Event 4000000/8094112\n",
      "Event 4500000/8094112\n",
      "Event 5000000/8094112\n",
      "Event 5500000/8094112\n",
      "Event 6000000/8094112\n",
      "Event 6500000/8094112\n",
      "Event 7000000/8094112\n",
      "Event 7500000/8094112\n",
      "Event 8000000/8094112\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h2_ntightleps_vs_ntotleps (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h2_ntightandIsoleps_vs_ntotleps (Potential memory leak).\n",
      "Info in <TCanvas::Print>: pdf file /cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/test/test03_th2f_totalleps_vs_tightleps.pdf has been created\n",
      "Info in <TCanvas::Print>: Current canvas added to pdf file /cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/test/test03_th2f_totalleps_vs_tightleps.pdf\n",
      "Info in <TCanvas::Print>: Current canvas added to pdf file /cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/test/test03_th2f_totalleps_vs_tightleps.pdf\n",
      "Info in <TCanvas::Print>: pdf file /cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/test/test03_th2f_totalleps_vs_tightleps.pdf has been closed\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "z_min = 0\n",
    "z_max = 5.5E6\n",
    "x_label = r\"Number of leptons per event\"\n",
    "\n",
    "h2_ntightleps_vs_ntotleps = make_TH2F(\"h2_ntightleps_vs_ntotleps\", title=\"Number of events with tight vs. total leptons\", \n",
    "              n_binsx=10, x_label=x_label,\n",
    "              x_units=None, x_min=2, x_max=12,\n",
    "              n_binsy=8, y_label=r\"Number of #bf{tight} leptons per event\",\n",
    "              y_units=None, y_min=0, y_max=8,\n",
    "              z_min=z_min, z_max=z_max, z_label_size=None,\n",
    "              n_contour=100)\n",
    "              \n",
    "h2_ntightandIsoleps_vs_ntotleps = make_TH2F(\"h2_ntightandIsoleps_vs_ntotleps\", title=\"Number of events with (tight & isolated) vs. total leptons\", \n",
    "              n_binsx=10, x_label=x_label,\n",
    "              x_units=None, x_min=2, x_max=12,\n",
    "              n_binsy=8, y_label=r\"Number of #bf{tight and isolated} leptons per event\",\n",
    "              y_units=None, y_min=0, y_max=8,\n",
    "              z_min=z_min, z_max=z_max, z_label_size=None,\n",
    "              n_contour=100)\n",
    "\n",
    "n_tot_entries = t_filippo_data2018.GetEntries()\n",
    "for ct, evt in enumerate(t_filippo_data2018):\n",
    "    if (ct % 500000) == 0:\n",
    "        print(f\"Event {ct}/{n_tot_entries}\")\n",
    "\n",
    "    lep_ls_id = list(evt.lep_id)\n",
    "    lep_ls_tightId = list(evt.lep_tightId)\n",
    "    lep_ls_RelIsoNoFSR = list(evt.lep_RelIsoNoFSR)\n",
    "    n_tot_leps = len(lep_ls_id)\n",
    "\n",
    "    # Check to see if each lepton is tight:\n",
    "    n_tightId_per_event = 0\n",
    "    n_tightId_and_RelIso_per_event = 0\n",
    "    for ndx in range(n_tot_leps):\n",
    "        is_tight = lep_ls_tightId[ndx]\n",
    "        if is_tight:\n",
    "            n_tightId_per_event += 1\n",
    "\n",
    "            # If we have a muon, see if it passed RelIso:\n",
    "            if abs(lep_ls_id[ndx]) == 13:\n",
    "                if lep_ls_RelIsoNoFSR[ndx] < 0.35:\n",
    "                    n_tightId_and_RelIso_per_event += 1\n",
    "\n",
    "    h2_ntightleps_vs_ntotleps.Fill(n_tot_leps, n_tightId_per_event, 1)\n",
    "    h2_ntightandIsoleps_vs_ntotleps.Fill(n_tot_leps, n_tightId_and_RelIso_per_event, 1)\n",
    "\n",
    "    # if ct > 10000: break\n",
    "\n",
    "outpdf_path = \"/cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/test/test03_th2f_totalleps_vs_tightleps.pdf\"\n",
    "\n",
    "hist_ls = [h2_ntightleps_vs_ntotleps, h2_ntightandIsoleps_vs_ntotleps]\n",
    "\n",
    "canv = TCanvas()\n",
    "style = setTDRStyle(pad_right_margin=0.15)\n",
    "gStyle.SetPaintTextFormat(\".3g\")\n",
    "gStyle.SetOptStat(0)\n",
    "\n",
    "canv.Print(outpdf_path + \"[\")\n",
    "for h2 in hist_ls:\n",
    "    h2.GetXaxis().CenterLabels()\n",
    "    h2.GetYaxis().CenterLabels()\n",
    "    h2.UseCurrentStyle()\n",
    "    h2.Draw(\"colz text\")\n",
    "    gPad.Update()\n",
    "    pave = make_pave_with_stats(h2, xmin=0.15, ymin=0.8, xmax=0.4, ymax=0.9)\n",
    "    pave.Draw(\"same\")\n",
    "    # statsbox = h2.FindObject(\"stats\")\n",
    "    # statsbox.SetX1NDC(0.55)\n",
    "    # statsbox.SetX2NDC(0.8)\n",
    "    # statsbox.SetY1NDC(0.8)\n",
    "    # statsbox.SetY2NDC(0.9)\n",
    "    canv.Print(outpdf_path)\n",
    "canv.Print(outpdf_path + \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#--- Save precious hists in a root file. ---#\n",
    "#############################################\n",
    "outrootfile = outpdf_path.replace(\".pdf\", \"_nleps2to12.root\")\n",
    "f_new = TFile.Open(outrootfile, \"recreate\")\n",
    "h2_ntightleps_vs_ntotleps.Write()\n",
    "h2_ntightandIsoleps_vs_ntotleps.Write()\n",
    "f_new.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Restore hists ---#\n",
    "f_hists = TFile(\"/cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/th2f_totalleps_vs_tightleps.root\", \"read\")\n",
    "h2_ntightleps_vs_ntotleps = f_hists.Get(\"h2_ntightleps_vs_ntotleps\")\n",
    "h2_ntightandIsoleps_vs_ntotleps = f_hists.Get(\"h2_ntightandIsoleps_vs_ntotleps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Convert to percent of all entries in TH2. ---#\n",
    "h2_ntightleps_vs_ntotleps_perc = h2_ntightleps_vs_ntotleps.Clone()\n",
    "h2_ntightleps_vs_ntotleps_perc.Scale(100.0/h2_ntightleps_vs_ntotleps.Integral())\n",
    "title = h2_ntightleps_vs_ntotleps_perc.GetTitle()\n",
    "h2_ntightleps_vs_ntotleps_perc.SetTitle(f\"{title} (as % of total integral)\")\n",
    "\n",
    "h2_ntightandIsoleps_vs_ntotleps_perc = h2_ntightandIsoleps_vs_ntotleps.Clone()\n",
    "h2_ntightandIsoleps_vs_ntotleps_perc.Scale(100.0/h2_ntightandIsoleps_vs_ntotleps.Integral())\n",
    "title = h2_ntightandIsoleps_vs_ntotleps_perc.GetTitle()\n",
    "h2_ntightandIsoleps_vs_ntotleps_perc.SetTitle(f\"{title} (as % of total integral)\")\n",
    "\n",
    "#--- Already normalized per column so just convert to a percentage. ---#\n",
    "h2_norm_ntightleps_vs_ntotleps = normalize_TH2_per_column(h2_ntightleps_vs_ntotleps)\n",
    "h2_norm_ntightleps_vs_ntotleps_perc = h2_norm_ntightleps_vs_ntotleps.Clone()\n",
    "h2_norm_ntightleps_vs_ntotleps_perc.Scale(100.0)\n",
    "title = h2_norm_ntightleps_vs_ntotleps_perc.GetTitle()\n",
    "h2_norm_ntightleps_vs_ntotleps_perc.SetTitle(f\"{title} (as % of total column)\")\n",
    "\n",
    "\n",
    "h2_norm_ntightandIsoleps_vs_ntotleps = normalize_TH2_per_column(h2_ntightandIsoleps_vs_ntotleps)\n",
    "h2_norm_ntightandIsoleps_vs_ntotleps_perc = h2_norm_ntightandIsoleps_vs_ntotleps.Clone()\n",
    "h2_norm_ntightandIsoleps_vs_ntotleps_perc.Scale(100.0)\n",
    "title = h2_norm_ntightandIsoleps_vs_ntotleps_perc.GetTitle()\n",
    "h2_norm_ntightandIsoleps_vs_ntotleps_perc.SetTitle(f\"{title} (as % of total column)\")\n",
    "\n",
    "#--- Final hists from here: ---#\n",
    "# h2_ntightleps_vs_ntotleps_perc, h2_ntightandIsoleps_vs_ntotleps_perc\n",
    "# h2_norm_ntightleps_vs_ntotleps_perc, h2_norm_ntightandIsoleps_vs_ntotleps_perc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Info in <TCanvas::Print>: pdf file /cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/test/allth2_totalleps_vs_tightleps_formatp2g.pdf has been created\nInfo in <TCanvas::Print>: Current canvas added to pdf file /cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/test/allth2_totalleps_vs_tightleps_formatp2g.pdf\nInfo in <TCanvas::Print>: Current canvas added to pdf file /cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/test/allth2_totalleps_vs_tightleps_formatp2g.pdf\nInfo in <TCanvas::Print>: Current canvas added to pdf file /cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/test/allth2_totalleps_vs_tightleps_formatp2g.pdf\nInfo in <TCanvas::Print>: Current canvas added to pdf file /cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/test/allth2_totalleps_vs_tightleps_formatp2g.pdf\nInfo in <TCanvas::Print>: Current canvas added to pdf file /cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/test/allth2_totalleps_vs_tightleps_formatp2g.pdf\nInfo in <TCanvas::Print>: Current canvas added to pdf file /cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/test/allth2_totalleps_vs_tightleps_formatp2g.pdf\nInfo in <TCanvas::Print>: pdf file /cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/test/allth2_totalleps_vs_tightleps_formatp2g.pdf has been closed\n"
     ]
    }
   ],
   "source": [
    "outpdf_path = \"/cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/test/allth2_totalleps_vs_tightleps_formatp2g.pdf\"\n",
    "markersize = 0.8  # 0.1, 0.01\n",
    "# printer = CanvasPrinter()\n",
    "# printer.make_plots_pretty(show_statsbox=False)\n",
    "\n",
    "# style = setTDRStyle(pad_right_margin=0.15)\n",
    "style = setTDRStyle()\n",
    "style.cd()\n",
    "style.SetPadRightMargin(0.15)\n",
    "\n",
    "canv = TCanvas()\n",
    "gStyle.SetOptStat(0)\n",
    "\n",
    "canv.Print(outpdf_path + \"[\")\n",
    "for h in (h2_ntightleps_vs_ntotleps, h2_ntightandIsoleps_vs_ntotleps):\n",
    "    gStyle.SetPaintTextFormat(\".2g\")\n",
    "    h.UseCurrentStyle()\n",
    "    h.SetMarkerSize(markersize)\n",
    "    h.GetZaxis().SetRangeUser(0, 5.5E6)\n",
    "    h.Draw(\"colz text\")\n",
    "    pave = make_pave_with_stats(h, xmin=0.15, ymin=0.8, xmax=0.4, ymax=0.9)\n",
    "    pave.Draw(\"same\")\n",
    "    # statsbox = h.FindObject(\"stats\")\n",
    "    # statsbox.SetX1NDC(0.55)\n",
    "    # statsbox.SetX2NDC(0.8)\n",
    "    # statsbox.SetY1NDC(0.8)\n",
    "    # statsbox.SetY2NDC(0.9)\n",
    "    # h.Draw(\"lego\")\n",
    "    # canv.Update()\n",
    "    # gPad.RedrawAxis()\n",
    "    # canv.RedrawAxis()\n",
    "    canv.Print(outpdf_path)\n",
    "\n",
    "for h in (h2_ntightleps_vs_ntotleps_perc, h2_ntightandIsoleps_vs_ntotleps_perc):\n",
    "    # h.SetTitle(h.GetTitle().rstrip(\" (%)\"))\n",
    "    # h.SetTitle(f\"{h.GetTitle()} (%)\")\n",
    "    # h.SetTitle(f\"{h.GetTitle()} (%)\")\n",
    "    gStyle.SetPaintTextFormat(\".2g%%\")\n",
    "    h.SetMarkerSize(markersize)\n",
    "    h.GetZaxis().SetRangeUser(0, 85.0)\n",
    "    h.Draw(\"colz text\")\n",
    "    pave = make_pave_with_stats(h, xmin=0.15, ymin=0.8, xmax=0.4, ymax=0.9)\n",
    "    pave.Draw(\"same\")\n",
    "    # statsbox = h.FindObject(\"stats\")\n",
    "    # statsbox.SetX1NDC(0.55)\n",
    "    # statsbox.SetX2NDC(0.8)\n",
    "    # statsbox.SetY1NDC(0.8)\n",
    "    # statsbox.SetY2NDC(0.9)\n",
    "    # h.Draw(\"lego\")\n",
    "    canv.Print(outpdf_path)\n",
    "\n",
    "for h in (h2_norm_ntightleps_vs_ntotleps_perc, h2_norm_ntightandIsoleps_vs_ntotleps_perc):\n",
    "    # h.SetTitle(h.GetTitle().rstrip(\" (%)\"))\n",
    "    # h.SetTitle(f\"{h.GetTitle()} (%)\")\n",
    "    # h.SetTitle(f\"{h.GetTitle()} (%)\")\n",
    "    gStyle.SetPaintTextFormat(\".2g%%\")\n",
    "    h.SetMarkerSize(markersize)\n",
    "    h.GetZaxis().SetRangeUser(0, 100.0)\n",
    "    h.Draw(\"colz text\")\n",
    "    pave = make_pave_with_stats(h, xmin=0.15, ymin=0.8, xmax=0.4, ymax=0.9)\n",
    "    pave.Draw(\"same\")\n",
    "    # statsbox = h.FindObject(\"stats\")\n",
    "    # statsbox.SetX1NDC(0.55)\n",
    "    # statsbox.SetX2NDC(0.8)\n",
    "    # statsbox.SetY1NDC(0.8)\n",
    "    # statsbox.SetY2NDC(0.9)\n",
    "    # h.Draw(\"lego\")\n",
    "    canv.Print(outpdf_path)\n",
    "canv.Print(outpdf_path + \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}