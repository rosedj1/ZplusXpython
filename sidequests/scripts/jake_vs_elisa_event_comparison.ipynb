{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "my_root_env",
   "display_name": "my_root_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer for Elisa's 3P1F and 2P2F event lists and for CJLST NTuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Welcome to JupyROOT 6.20/04\n"
     ]
    }
   ],
   "source": [
    "# Execute `voms-proxy-init` in the shell before starting this JupyNB.\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from ROOT import TFile\n",
    "\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "top_dir = \"/blue/avery/rosedj1/\"\n",
    "# sys.path.append(top_dir)\n",
    "\n",
    "# top_dir = \"/afs/cern.ch/work/d/drosenzw/zplusx/\"\n",
    "_ = [sys.path.append(os.path.join(top_dir, package)) for package in (\"HiggsMassMeasurement\", \"ZplusXpython\")]\n",
    "# from Utils_Python.Utils_Files import check_overwrite\n",
    "from sidequests.data.cjlst_fw import CjlstFlag\n",
    "from Utils_Python.Commands import shell_cmd\n",
    "from Utils_Python.Utils_Files import save_to_json, open_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_matteo_data2018 = \"/eos/cms/store/group/phys_higgs/cmshzz4l/cjlst/RunIILegacy/200430_LegacyRun2/Data_2018/AllData/ZZ4lAnalysis.root\"\n",
    "t_matteo_up = uproot.open(f\"root://eoscms.cern.ch/{infile_matteo_data2018}:CRZLLTree/candTree\", timeout=180)\n",
    "\n",
    "runnum_arr = t_matteo_up[\"RunNumber\"].array(library=\"np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tree_info_to_txt(infile, outtxt, keep_2P2F=True, keep_3P1F=True):\n",
    "    \"\"\"\n",
    "    Write info from TFile `infile` from TTree 'passedEvents' to `outtxt`.\n",
    "\n",
    "    Info which gets written:\n",
    "    Run : LumiSect : Event\n",
    "    \"\"\"\n",
    "    tfile = rt.TFile.Open(infile)\n",
    "    tree = tfile.Get(\"passedEvents\")\n",
    "\n",
    "    with open(outtxt, \"w\") as f:\n",
    "        f.write(\"# Run : LumiSect : Event\\n\")\n",
    "        for evt in tree:\n",
    "            keep_evt = True if (keep_2P2F and evt.is2P2F) or (keep_3P1F and evt.is3P1F) else False\n",
    "            if keep_evt:\n",
    "                f.write(f\"{evt.Run} : {evt.LumiSect} : {evt.Event}\\n\")\n",
    "    print(f\"TTree info written to:\\n{outtxt}\")\n",
    " \n",
    "def get_list_of_lines(evt_ls_txt):\n",
    "    \"\"\"\n",
    "    Return a list of the lines from `evt_ls_txt`.\n",
    "    The lines must start with a digit.\n",
    "    Trailing newlines ('\\\\n') are stripped.\n",
    "    \"\"\"\n",
    "    with open(evt_ls_txt, \"r\") as f:\n",
    "        return [line.rstrip('\\n') for line in f.readlines() if line[0].isdigit()]\n",
    "\n",
    "def get_list_of_tuples(evt_ls):\n",
    "    \"\"\"\n",
    "    Return a list of 3-tuples from a list of strings `evt_ls`:\n",
    "\n",
    "    [\n",
    "        (Run1, LumiSect1, Event1),\n",
    "        (Run2, LumiSect2, Event2),\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    new_evt_ls = []\n",
    "    for line in evt_ls:\n",
    "        tup = tuple([int(num) for num in line.split(\":\")[:3]])\n",
    "        new_evt_ls.append(tup)\n",
    "    return new_evt_ls\n",
    "\n",
    "def print_evt_info_bbf(tree):\n",
    "    print(f\"tree.passedFullSelection: {tree.passedFullSelection}\")\n",
    "    print(f\"tree.passedZXCRSelection: {tree.passedZXCRSelection}\")\n",
    "    print(f\"tree.nZXCRFailedLeptons: {tree.nZXCRFailedLeptons}\")\n",
    "    print(f\"tree.lep_Hindex: {list(tree.lep_Hindex)}\")\n",
    "    print(f\"tree.lepFSR_pt: {list(tree.lepFSR_pt)}\")\n",
    "    print(f\"tree.lep_RelIso: {list(tree.lep_RelIso)}\")\n",
    "    print(f\"tree.lep_id: {list(tree.lep_id)}\")\n",
    "    print(f\"tree.lep_tightId: {list(tree.lep_tightId)}\")\n",
    "    print(\"#--- PRINT MORE Z AND H INFO HERE. ---#\")\n",
    "\n",
    "def print_evt_info_cjlst(tree):\n",
    "    print(f\"tree.LepPt: {list(tree.LepPt)}\")\n",
    "    print(f\"tree.LepLepId: {list(tree.LepLepId)}\")\n",
    "    print(f\"tree.LepisID (tight lep): {list(np.array(tree.LepisID, dtype=bool))}\")\n",
    "    print(f\"tree.LepisID (tight lep): {list(np.array(tree.LepisID, dtype=bool))}\")\n",
    "    print(f\"tree.CRflag: {tree.CRflag} -> {CjlstFlag(tree.CRflag).name}\")\n",
    "    print(f\"tree.Z1Mass: {tree.Z1Mass}\")\n",
    "    print(f\"tree.Z2Mass: {tree.Z2Mass}\")\n",
    "    print(f\"tree.ZZMass: {tree.ZZMass}\")\n",
    "    print()\n",
    "\n",
    "def analyze_single_evt(tree, run, lumi, event, fw=\"bbf\", which=\"all\", evt_start=0, print_every=10000):\n",
    "    \"\"\"Print out event info (`run`:`lumi`:`event`) found in `tree`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fw : str\n",
    "        Which framework to use: \"bbf\", \"cjlst\"\n",
    "    which : str\n",
    "        Which instance of the event you want to select.\n",
    "        Options: \"first\", anything else prints all such events.\n",
    "    evt_start : int\n",
    "    \"\"\"\n",
    "    print(f\"Searching for event ID {run}:{lumi}:{event} in {fw.upper()} framework\")\n",
    "\n",
    "    n_tot = tree.GetEntries()\n",
    "    for evt_num in range(evt_start, n_tot):\n",
    "        tree.GetEntry(evt_num)\n",
    "        if (evt_num % print_every) == 0:\n",
    "            print(f\"Event {evt_num}/{n_tot}\")\n",
    "\n",
    "        if fw in \"bbf\":\n",
    "            if tree.Run != run:\n",
    "                continue\n",
    "            if tree.LumiSect != lumi:\n",
    "                continue\n",
    "            if tree.Event != event:\n",
    "                continue\n",
    "            if not tree.passedZXCRSelection:\n",
    "                print(f\"[WARNING] Event has passedZXCRSelection == 0.\")\n",
    "            print(f\"Event {run}:{lumi}:{event} found. Index: {evt_num}\")\n",
    "            print_evt_info_bbf(tree)\n",
    "\n",
    "        elif fw in \"cjlst\":\n",
    "            if tree.RunNumber != run:\n",
    "                continue\n",
    "            if tree.LumiNumber != lumi:\n",
    "                continue\n",
    "            if tree.EventNumber != event:\n",
    "                continue\n",
    "            print(f\"Event {run}:{lumi}:{event} found. Index: {evt_num}\")\n",
    "            print_evt_info_cjlst(tree)\n",
    "\n",
    "        if \"first\" in which:\n",
    "            break\n",
    "    print(\"Done.\")\n",
    "\n",
    "def get_control_region(evt):\n",
    "    \"\"\"Return str of control region based on `lep_Hindex` and `lep_tightId`.\n",
    "\n",
    "    Only works for BBF root files.\n",
    "    \"\"\"\n",
    "    l_Hindex_ls = list(evt.lep_Hindex)\n",
    "    assert -1 not in l_Hindex_ls\n",
    "    l_tightId_arr = np.array(evt.lep_tightId)[l_Hindex_ls]\n",
    "\n",
    "    # 3P1F is defined as 3 leptons passing tight and ISO criteria:\n",
    "    l_RelIsoNoFSR_arr = np.array(evt.lep_RelIsoNoFSR)[l_Hindex_ls]\n",
    "    # muons_arr = \n",
    "    # l_RelIsoNoFSR_arr\n",
    "    s = l_tightId_arr.sum()\n",
    "\n",
    "    if s == 4:\n",
    "        return \"SR\"\n",
    "    elif s == 3:\n",
    "        return \"3P1F\"\n",
    "    elif s == 2:\n",
    "        return \"2P2F\"\n",
    "    else:\n",
    "        return f\"[WARNING] Could not assign number of tight leps ({s}) to a CR!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileComparer:\n",
    "\n",
    "    def __init__(self, txt_file1, txt_file2, control_reg=\"\", verbose=False):\n",
    "        \"\"\"\n",
    "        Feed in two txt files to be compared.\n",
    "\n",
    "        NOTE:\n",
    "        - Each txt file is converted to a list of 3-tuples and stored.\n",
    "        - Only lines which begin with a digit are read and stored.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        control_reg : str\n",
    "            Used for printing and writing files.\n",
    "        \"\"\"\n",
    "        self.file1 = txt_file1\n",
    "        self.file2 = txt_file2\n",
    "        self.cr = control_reg\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.check_cr(txt_file1, txt_file2)\n",
    "        if control_reg in \"\":\n",
    "            self.cr = \"all\"\n",
    "        self.ls_of_tup_file1_nodup = None\n",
    "        self.ls_of_tup_file2_nodup = None\n",
    "\n",
    "        # Check for duplicates.\n",
    "        self.ls_of_tup_file1 = get_list_of_tuples(get_list_of_lines(txt_file1))\n",
    "        if self.check_for_dups(txt_file1, self.ls_of_tup_file1):\n",
    "            # Remove duplicates by turning to a set and then back to list.\n",
    "            self.ls_of_tup_file1_nodup = list(set(self.ls_of_tup_file1))\n",
    "        else:\n",
    "            self.ls_of_tup_file1_nodup = self.ls_of_tup_file1\n",
    "\n",
    "        self.ls_of_tup_file2 = get_list_of_tuples(get_list_of_lines(txt_file2))\n",
    "        if self.check_for_dups(txt_file2, self.ls_of_tup_file2):\n",
    "            self.ls_of_tup_file2_nodup = list(set(self.ls_of_tup_file2))\n",
    "        else:\n",
    "            self.ls_of_tup_file2_nodup = self.ls_of_tup_file2\n",
    "\n",
    "        self.compare_files()\n",
    "\n",
    "    def check_for_dups(self, txt_file, ls_of_tup):\n",
    "        \"\"\"Return True and print info if duplicates within a file are found.\"\"\"\n",
    "        len_ls = len(ls_of_tup)\n",
    "        len_set = len(set(ls_of_tup))\n",
    "        if len_ls != len_set:\n",
    "            n_dups = len_ls - len_set\n",
    "            print(f\"[WARNING] Duplicates ({n_dups}) found in file: {txt_file}\")\n",
    "            print(f\"[WARNING] len(ls)={len_ls} != len(set)={len_set}\")\n",
    "            if self.verbose:\n",
    "                # There's some counting error here...\n",
    "                # I know there are 120 duplicates, but counter only finds 118.\n",
    "                counter = Counter(ls_of_tup)\n",
    "                print(f\"Printing duplicates in file:\\n{txt_file}\")\n",
    "                dup_key_ls = [k for k,v in counter.items() if v > 1]\n",
    "                # pprint(dup_key_ls)\n",
    "                # assert n_dups == len(dup_key_ls)\n",
    "                pprint(dup_key_ls)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def check_cr(self, path1, path2):\n",
    "        \"\"\"Make sure that the control region is the one requested.\"\"\"\n",
    "        cr_low = self.cr.lower()\n",
    "        assert cr_low in (\"2p2f\", \"3p1f\", \"\")\n",
    "        # Make sure that the two files have the requested CR.\n",
    "        msg = f\"The `control_reg` ({self.cr}) not found in names of txt files.\"\n",
    "        assert all(cr_low in f.lower() for f in (path1, path2)), msg\n",
    "\n",
    "    def compare_files(self):\n",
    "        \"\"\"Store unique and common info about files. Called when instantiated.\"\"\"\n",
    "        self.set_common_to_both = set(self.ls_of_tup_file1_nodup) & set(self.ls_of_tup_file2_nodup)\n",
    "        self.set_unique_to_file1 = set(self.ls_of_tup_file1_nodup) - set(self.ls_of_tup_file2_nodup)\n",
    "        self.set_unique_to_file2 = set(self.ls_of_tup_file2_nodup) - set(self.ls_of_tup_file1_nodup)\n",
    "\n",
    "    def print_results(self, whose=\"all\", show_n_evts=25, save_to_file=None):\n",
    "        \"\"\"Print info describing differences between two files.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        whose : str\n",
    "            \"file1\", \"file2\", \"all\"\n",
    "        \"\"\"\n",
    "        print(f\"Comparing {self.cr.upper()}:\")\n",
    "        print(f\"file1: {self.file1}\")\n",
    "        print(f\"file2: {self.file2}\")\n",
    "\n",
    "        print(f\"{'n_evts total file1 (no dup): ':<25}{len(self.ls_of_tup_file1_nodup)}\")\n",
    "        print(f\"{'n_evts total file2 (no dup): ':<25}{len(self.ls_of_tup_file2_nodup)}\")\n",
    "        print(f\"{'n_evts in common: ':<25}{len(self.set_common_to_both)}\")\n",
    "        print(f\"{'n_evts unique to file1: ':<25}{len(self.set_unique_to_file1)}\")\n",
    "        print(f\"{'n_evts unique to file2: ':<25}{len(self.set_unique_to_file2)}\")\n",
    "\n",
    "        header = \"#-- Run -- LumiSect -- Event --#\"\n",
    "        if show_n_evts == -1:\n",
    "            show_n_evts = None\n",
    "        if whose in (\"file1\", \"all\"):\n",
    "            print(f\"  file1's unique events:\")\n",
    "            print(header)\n",
    "            pprint(list(self.set_unique_to_file1)[:show_n_evts])\n",
    "            print()\n",
    "        if whose in (\"file2\", \"all\"):\n",
    "            print(f\"  file2's unique events:\")\n",
    "            print(header)\n",
    "            pprint(list(self.set_unique_to_file2)[:show_n_evts])\n",
    "            print()\n",
    "\n",
    "    def save_events_to_txt(self, kind, outtxt, no_dup=True, overwrite=False):\n",
    "        \"\"\"\n",
    "        Write the events to `outtxt` in the format:\n",
    "\n",
    "        Run : LumiSect : Event\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        kind : str\n",
    "            Choose which events to write to `outtxt`.\n",
    "            \"file1\", \"file2\", \"common\", \"file1_unique\", \"file2_unique\"\n",
    "        \"\"\"\n",
    "        check_overwrite(outtxt, overwrite=overwrite)\n",
    "        assert kind in (\"file1\", \"file2\", \"common\", \"file1_unique\", \"file2_unique\")\n",
    "\n",
    "        if kind in \"file1\":\n",
    "            iter_ls_of_tup = self.ls_of_tup_file1_nodup if no_dup else self.ls_of_tup_file1\n",
    "        elif kind in \"file2\":\n",
    "            iter_ls_of_tup = self.ls_of_tup_file2_nodup if no_dup else self.ls_of_tup_file2\n",
    "        elif kind in \"common\":\n",
    "            iter_ls_of_tup = self.set_common_to_both\n",
    "        elif kind in \"file1_unique\":\n",
    "            iter_ls_of_tup = self.set_unique_to_file1\n",
    "        elif kind in \"file2_unique\":\n",
    "            iter_ls_of_tup = self.set_unique_to_file2\n",
    "\n",
    "        with open(outtxt, \"w\") as f:\n",
    "            f.write(\"# Run : LumiSect : Event\\n\")\n",
    "            for tup in iter_ls_of_tup:\n",
    "                f.write(f\"{tup[0]} : {tup[1]} : {tup[2]}\\n\")\n",
    "            print(f\"Wrote '{self.cr} {kind}' events to file:\\n{outtxt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile_jake_tree = \"/blue/avery/rosedj1/ZplusXpython/data/ZLL_CR_FRapplied/Data_2018_NoDuplicates_RunEventLumi.root\"\n",
    "infile_jake_tree = \"/blue/avery/rosedj1/ZplusXpython/data/ZLL_CR_FRapplied/new_data2018/cr_ZLL.root\"\n",
    "# ^Contains all the passedZXCRSelection events as in:\n",
    "# /fullstats/ZL_ZLL_4P_CR/noduplicates/Data2018_NoDuplicates.root\n",
    "\n",
    "#####################\n",
    "#--- CJLST files ---#\n",
    "#####################\n",
    "infile_elisa       = \"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/CRLLos_listOfEvents.txt\"\n",
    "infile_elisa_2p2f  = \"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/CRLLos_2P2F_listOfEvents.txt\"\n",
    "infile_elisa_3p1f  = \"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/CRLLos_3P1F_listOfEvents.txt\"\n",
    "infile_matteo_data2018 = \"/eos/cms/store/group/phys_higgs/cmshzz4l/cjlst/RunIILegacy/200430_LegacyRun2/Data_2018/AllData/ZZ4lAnalysis.root\"\n",
    "infile_cjlst_sr = \"/blue/avery/rosedj1/ZplusXpython/sidequests/data/2018_CJLST_finalSelectedEvents_SR.txt\"\n",
    "\n",
    "elisa_3p1f_unique_evtid_dct_json = \"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/elisa_3p1f_unique_evtID_CR_dct.json\"\n",
    "\n",
    "\n",
    "outdir = \"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/jakes_new2018data/\"\n",
    "\n",
    "infile_jake      = os.path.join(outdir, \"CRLLos_listOfEvents_jake.txt\")\n",
    "infile_jake_2p2f = os.path.join(outdir, \"CRLLos_listOfEvents_jake_2P2F.txt\")\n",
    "infile_jake_3p1f = os.path.join(outdir, \"CRLLos_listOfEvents_jake_3P1F.txt\")\n",
    "infile_elisa_unique_353 = \"/blue/avery/rosedj1/ZplusXpython/sidequests/rootfiles/elisa_unique_353events.root\"\n",
    "\n",
    "outfile_elisa_2p2f_unique  = os.path.join(outdir, \"CRLLos_2P2F_listOfEvents_unique.txt\")\n",
    "outfile_elisa_3p1f_unique  = os.path.join(outdir, \"CRLLos_3P1F_listOfEvents_unique.txt\")\n",
    "outfile_jake_2p2f_unique = os.path.join(outdir, \"CRLLos_listOfEvents_jake_2P2F_unique.txt\")\n",
    "outfile_jake_3p1f_unique = os.path.join(outdir, \"CRLLos_listOfEvents_jake_3P1F_unique.txt\")\n",
    "outfile_LLR_data2018 = \"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/\"\n",
    "\n",
    "outfile_2p2f_common = os.path.join(outdir, \"CRLLos_listOfEvents_2P2F_common.txt\")\n",
    "outfile_3p1f_common = os.path.join(outdir, \"CRLLos_listOfEvents_3P1F_common.txt\")\n",
    "# write_tree_info_to_txt(infile_jake_tree, infile_jake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make txt files of events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tree_info_to_txt(infile_jake_tree, infile_jake_2p2f, keep_2P2F=True, keep_3P1F=False)\n",
    "write_tree_info_to_txt(infile_jake_tree, infile_jake_3p1f, keep_2P2F=False, keep_3P1F=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_elisa_2p2fvs3p1f = FileComparer(infile_elisa_2p2f, infile_elisa_3p1f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fc_jakevselisa_3p1f = FileComparer(infile_jake_3p1f, infile_elisa_3p1f, control_reg=\"3p1f\", verbose=True)\n",
    "fc_jakevselisa_2p2f = FileComparer(infile_jake_2p2f, infile_elisa_2p2f, control_reg=\"2p2f\", verbose=True)\n",
    "fc_jakevselisa_all  = FileComparer(infile_jake, infile_elisa, control_reg=\"\", verbose=True)\n",
    "\n",
    "# fc_jakevselisa_3p1f.print_results(whose=\"file1\", show_n_evts=5)\n",
    "# fc_jakevselisa_3p1f.print_results(whose=\"file2\", show_n_evts=5)\n",
    "# fc_jakevselisa_2p2f.print_results(whose=\"file1\", show_n_evts=5)\n",
    "# fc_jakevselisa_2p2f.print_results(whose=\"file2\", show_n_evts=5)\n",
    "# # fc_jakevselisa_all.print_results(whose=\"all\", show_n_evts=10)\n",
    "\n",
    "# # Write the events to txt.\n",
    "# overwrite = 0\n",
    "# fc_jakevselisa_3p1f.save_events_to_txt(kind=\"file1_unique\", outtxt=outfile_jake_3p1f_unique, no_dup=True, overwrite=overwrite)\n",
    "# fc_jakevselisa_3p1f.save_events_to_txt(kind=\"file2_unique\", outtxt=outfile_elisa_3p1f_unique, no_dup=True, overwrite=overwrite)\n",
    "# fc_jakevselisa_3p1f.save_events_to_txt(kind=\"common\", outtxt=outfile_3p1f_common, no_dup=True, overwrite=overwrite)\n",
    "\n",
    "# fc_jakevselisa_2p2f.save_events_to_txt(kind=\"file1_unique\", outtxt=outfile_jake_2p2f_unique, no_dup=True, overwrite=overwrite)\n",
    "# fc_jakevselisa_2p2f.save_events_to_txt(kind=\"file2_unique\", outtxt=outfile_elisa_2p2f_unique, no_dup=True, overwrite=overwrite)\n",
    "# fc_jakevselisa_2p2f.save_events_to_txt(kind=\"common\", outtxt=outfile_2p2f_common, no_dup=True, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fc_jakevselisa_all.ls_of_tup_file2) - len(fc_jakevselisa_all.ls_of_tup_file2_nodup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a manual counter.\n",
    "# Print out events which appear more than once in fc_jakevselisa_all.ls_of_tup_file2.\n",
    "for f in fc_jakevselisa_all.ls_of_tup_file2:\n",
    "    ct = 0\n",
    "    if f in fc_jakevselisa_all.ls_of_tup_file2_nodup:\n",
    "        if ct == 5: break\n",
    "        print(f)\n",
    "# Identify the 2 events from 120 which didn't appear in 118.\n",
    "# Why did counter not find them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLR Group's (diff. xs) RedBkg Files\n",
    "\n",
    "Vukasin pointed me to their root files:\n",
    "\n",
    "- `/afs/cern.ch/user/v/vmilosev/public/forJake/new_ZX_LLR/AllData*`\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_llr_2018 = \"/blue/avery/rosedj1/ZplusXpython/sidequests/data/LLR_redbkg/AllData_ZX_redTree_2018.root\"\n",
    "\n",
    "f_llr = TFile(infile_llr_2018)\n",
    "t_llr = f_llr.Get(\"SelectedTree\")\n",
    "\n",
    "odd_event = (315488, 152, 135937874, )\n",
    "\n",
    "n_tot_evts = t_llr.GetEntries()\n",
    "for evt_num, evt in enumerate(t_llr):\n",
    "    if (evt_num % 500) == 0:\n",
    "        print(f\"Checking event #{evt_num}/{n_tot_evts}\")\n",
    "    if evt.RunNumber != odd_event[0]:\n",
    "        continue\n",
    "    if evt.LumiNumber != odd_event[1]:\n",
    "        continue\n",
    "    if evt.EventNumber != odd_event[2]:\n",
    "        continue\n",
    "    print(f\"Event found ({evt.RunNumber}:{evt.LumiNumber}:{evt.EventNumber}) at index {evt_num}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(t.GetListOfBranches())\n",
    "\n",
    "t.Scan(\"htxs_stage1_red_cat:htxs_stage1_red_catName:htxs_stage1_red_prod_cat:htxs_stage1_red_prod_catName\")\n",
    "\n",
    "#--- Counting instances of htxs_stage1 ---#\n",
    "# htxs_stage1_red_catName_ls = [str(evt.htxs_stage1_red_catName) for evt in t if evt.htxs_stage1_red_catName == 'ZX']\n",
    "# count_ZX_str = Counter(htxs_stage1_red_catName_ls)\n",
    "htxs_stage1_red_cat_ls = [str(evt.htxs_stage1_red_cat) for evt in t if evt.htxs_stage1_red_cat == -2]\n",
    "count_ZX_cat = Counter(htxs_stage1_red_cat_ls)\n",
    "# dup_key_ls = [k for k,v in counter.items() if v > 1]\n",
    "print(count_ZX_cat)\n",
    "\n",
    "t.GetEntries()  # 12331\n",
    "\n",
    "#--- Tried to match any of Elisa's ZLL events to diff. xs group's events.\n",
    "#--- None matched.\n",
    "elisa_evtid_2p2f_tup = get_list_of_tuples(get_list_of_lines(infile_elisa_2p2f))\n",
    "n_tot_tup = len(elisa_evtid_2p2f_tup)\n",
    "start_at = 1000\n",
    "for num_tup, tup in enumerate(elisa_evtid_2p2f_tup[start_at:], start_at):\n",
    "    if (num_tup % 1000) == 0:\n",
    "        print(f\"Checking tuple #{num_tup}/{n_tot_tup}\")\n",
    "    for evt_num, evt in enumerate(t):\n",
    "        if evt.RunNumber != elisa_evtid_2p2f_tup_example[0]:\n",
    "            continue\n",
    "        if evt.LumiNumber != elisa_evtid_2p2f_tup_example[1]:\n",
    "            continue\n",
    "        if evt.EventNumber != elisa_evtid_2p2f_tup_example[2]:\n",
    "            continue\n",
    "        print(f\"Event {evt_num}, {evt.RunNumber}:{evt.LumiNumber}:{evt.EventNumber}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "These are Diff. XS Group's SR samples.\n",
    "They do not contain RedBkg info.\n",
    "\n",
    "### So What Next?\n",
    "\n",
    "Matteo gave me a CJLST 2018 Data NTuple to look at.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify duplicate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of 3P1F, 2P2F, and SS events in CJLST NTuples:\n",
    "for c in CjlstFlag:\n",
    "    conreg = c.name\n",
    "    n = t_matteo.GetEntries(f\"CRflag == {c}\")\n",
    "    print(f\"Number of {conreg} entries: {n}\")\n",
    "# Output:\n",
    "# Number of CR3P1F entries: 4806  (after removing duplicate -> 4805)\n",
    "# Number of CR2P2F entries: 46067 (after removing duplicate -> 46066)\n",
    "# Number of CRLLss entries: 50144\n",
    "# I believe there is one duplicate in 3P1F and 2P2F:\n",
    "# 315512 : 947 : 703286863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building CJLST event analyzer.\n",
    "dup = (315512, 947, 703286863)\n",
    "ct = 0\n",
    "dup_dict = {}\n",
    "    for evt_num, evt in enumerate(t):\n",
    "        if evt.RunNumber != :\n",
    "            continue\n",
    "        if evt.LumiNumber != :\n",
    "            continue\n",
    "        if evt.EventNumber != :\n",
    "            continue\n",
    "    ct += 1\n",
    "    dup_dict[evt_num] = (evt.RunNumber, evt.LumiNumber, evt.EventNumber, evt.Z1Mass, evt.Z2Mass, evt.ZZMass,)\n",
    "    if ct > 1:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guinea_pig_tup = (315512, 947, 703286863, )\n",
    "for evt_num, evt in enumerate(t_jake_2018data):\n",
    "    if evt.Run != guinea_pig_tup[0]:\n",
    "        continue\n",
    "    if evt.LumiSect != guinea_pig_tup[1]:\n",
    "        continue\n",
    "    if evt.Event != guinea_pig_tup[2]:\n",
    "        continue\n",
    "    print(f\"Event number {evt_num}.\")\n",
    "    print(f\"lep_pt: {list(evt.lep_pt)}\")\n",
    "    print(f\"lep_FSRpt: {list(evt.lep_FSRpt)}\")\n",
    "    break\n",
    "\n",
    "\n",
    "# t_jake_2018data.GetEntry(660)\n",
    "print(f\"t_jake_2018data.lep_Hindex: {list(t_jake_2018data.lep_Hindex)}\")\n",
    "print(f\"t_jake_2018data.lepFSR_pt: {list(t_jake_2018data.lepFSR_pt)}\")\n",
    "print(f\"t_jake_2018data.lep_RelIso: {list(t_jake_2018data.lep_RelIso)}\")\n",
    "print(f\"t_jake_2018data.lep_id: {list(t_jake_2018data.lep_id)}\")\n",
    "print(f\"t_jake_2018data.lep_tightId: {list(t_jake_2018data.lep_tightId)}\")\n",
    "# print(f\"t_jake_2018data.lep_tightId: {t_jake_2018data.lep_tightId}\")\n",
    "# print(f\"t_jake_2018data.lep_RelIsoNoFSR: {t_jake_2018data.RelIsoNoFSR}\")\n",
    "\n",
    "# print(f\"t_jake_2018data.lep_id: {t_jake_2018data.lep_id}\")\n",
    "\n",
    "t_jake_2018data.passedZXCRSelection\n",
    "print(t_jake_2018data.Run)\n",
    "print(t_jake_2018data.LumiSect)\n",
    "print(t_jake_2018data.Event)\n",
    "\n",
    "# elisa_unique_event_3p1f_325159_181_259586791.root\n",
    "unique_3p1f_evt = (321973, 1133, 1973286739,)\n",
    "for evt_num, evt in enumerate(t_jake_2018data):\n",
    "    if evt.Run != unique_3p1f_evt[0]:\n",
    "        continue\n",
    "    if evt.LumiSect != unique_3p1f_evt[1]:\n",
    "        continue\n",
    "    if evt.Event != unique_3p1f_evt[2]:\n",
    "        continue\n",
    "    print(f\"Event number {evt_num}.\")\n",
    "    print(f\"lep_pt: {list(evt.lep_pt)}\")\n",
    "    print(f\"lep_FSRpt: {list(evt.lep_FSRpt)}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import TFile\n",
    "f_matteo = TFile.Open(f\"root://eoscms.cern.ch/{infile_matteo_data2018}\")\n",
    "t_matteo = f_matteo.Get(\"CRZLLTree/candTree\")\n",
    "print(f\"File opened:\\n{infile_matteo_data2018}\")\n",
    "\n",
    "f_jake = TFile.Open(infile_jake_tree)\n",
    "t_jake = f_jake.Get(\"passedEvents\")\n",
    "\n",
    "f_elisa_353 = TFile(infile_elisa_unique_353)\n",
    "t_elisa_353 = f_elisa_353.Get(\"Ana/passedEvents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a `dict` (all CJLST eventIDs : CRs) and then look for Elisa's unique events.\n",
    "\n",
    "- All of Elisa's events were (of course) found in the CJLST NTuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tot_cjlst = t_matteo.GetEntries()\n",
    "cjlst_evtid_dct = {}\n",
    "for evt_num, evt in enumerate(t_matteo):\n",
    "    if (evt_num % 5000) == 0:\n",
    "        print(f\"CJLST TTree at entry: {evt_num}/{n_tot_cjlst}\")\n",
    "    key = f\"{evt.RunNumber} : {evt.LumiNumber} : {evt.EventNumber}\"\n",
    "    this_single_cr_ls = [CjlstFlag(evt.CRflag).name]\n",
    "    if key not in cjlst_evtid_dct.keys():\n",
    "        cjlst_evtid_dct[key] = this_single_cr_ls\n",
    "    else:\n",
    "        # Event with this Run:Lumi:Event has already been stored.\n",
    "        # This entry contains a new CR (by combining different leptons).\n",
    "        cjlst_evtid_dct[key].extend(this_single_cr_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "outfile = \"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/cjlst_evtID_CR_dct.json\"\n",
    "\n",
    "with open(outfile, 'w') as f:\n",
    "    json.dump(cjlst_evtid_dct, f, indent=4, sort_keys=False)\n",
    "print(f\"[INFO] JSON file written:\\n{outfile}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cjlst_evtid_dct = open_json(\"/blue/avery/rosedj1/ZplusXpython/sidequests/findmissingevents_comparetoelisa/cjlst_evtID_CR_dct.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dict (Elisa's eventIDs : CRs).\n",
    "elisa_3p1f_unique_ls_tup = get_list_of_tuples(get_list_of_lines(outfile_elisa_3p1f_unique))\n",
    "\n",
    "n_tot_uniq = len(elisa_3p1f_unique_ls_tup)\n",
    "n_tot_cjlst = t_matteo.GetEntries()\n",
    "elisa_3p1f_unique_evtid_dct = {}\n",
    "\n",
    "for unique_evt_num, evt_id in enumerate(elisa_3p1f_unique_ls_tup, 1):\n",
    "    if (unique_evt_num % 100) == 0:\n",
    "        print(f\"Searching for Elisa's unique event {unique_evt_num}/{n_tot_uniq}: {evt_id}\")\n",
    "    elisa_key = f\"{evt_id[0]} : {evt_id[1]} : {evt_id[2]}\"\n",
    "    elisa_3p1f_unique_evtid_dct[elisa_key] = cjlst_evtid_dct[elisa_key]\n",
    "\n",
    "save_to_json(elisa_3p1f_unique_evtid_dct, elisa_3p1f_unique_evtid_dct_json, overwrite=False, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now study the properties of CJLST's unique 3P1F events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter(elisa_3p1f_unique_evtid_dct.keys())\n",
    "# list(elisa_3p1f_unique_evtid_dct.values())[:15]\n",
    "ct = 0\n",
    "for uniq_evtID, cr in elisa_3p1f_unique_evtid_dct.items():\n",
    "    # if (\"CR3P1F\" in cr) and (len(cr) == 1):\n",
    "    if \"CR2P2F\" in cr:\n",
    "        print(f\"eventID = {uniq_evtID}, CR = {cr}\")\n",
    "        ct += 1\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do any of the unique events also belong to SR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Make a dict(CJLST's SR eventID : CR) events. ---#\n",
    "# cjlst_sr_ls_tup = get_list_of_tuples(get_list_of_lines(infile_cjlst_sr))\n",
    "# cjlst_evtid_sr_dct = {k:['SR'] for k in cjlst_sr_ls_tup}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elisa_3p1f_unique_evtid_dct = open_json(elisa_3p1f_unique_evtid_dct_json)\n",
    "elisa_3p1fonly_unique_ls = [k for k,v in elisa_3p1f_unique_evtid_dct.items() if len(v) == 1 and 'CR3P1F' in v]\n",
    "\n",
    "# set(cjlst_evtid_sr_dct.keys()) & set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few of Elisa's unique 3P1F events that belong to ONLY 3P1F:\n",
    "elisa_3p1fonly_unique_ls[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_elisa_353 = BBF TTree, edmPickEvents on all of Elisa's unique 3P1F events.\n",
    "analyze_single_evt(t_elisa_353, 321973, 1133, 1973286739, fw=\"bbf\", which=\"all\", evt_start=0, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_single_evt(t_elisa_353, run, lumi, event, fw=\"bbf\", which=\"all\", evt_start=0, print_every=1000)\n",
    "analyze_single_evt(t_elisa_353, 321973, 1133, 1973286739, fw=\"cjlst\", which=\"all\", evt_start=0, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elisa_3p1fonly_unique_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(elisa_3p1fonly_unique_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_elisa_353_evtls = [(evt.Run, evt.LumiSect, evt.Event, ) for evt in t_elisa_353]\n",
    "set_elisa_353_evt = set(t_elisa_353_evtls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elisa_3p1fonly_unique_set = set()\n",
    "for evtid in elisa_3p1fonly_unique_ls:\n",
    "    str_ls = evtid.split(\":\")\n",
    "    str_ls = [s.rstrip().lstrip() for s in str_ls]\n",
    "    run = int(str_ls[0])\n",
    "    lumi = int(str_ls[1])\n",
    "    event = int(str_ls[2])\n",
    "    elisa_3p1fonly_unique_set.add((run, lumi, event, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrsct_353evt_and_elisa3p1fonlyunique_ls = list(set_elisa_353_evt & elisa_3p1fonly_unique_set)\n",
    "ntrsct_353evt_and_elisa3p1fonlyunique_ls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ntrsct_353evt_and_elisa3p1fonlyunique_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_single_evt(t_matteo, 322430, 331, 543297179, fw=\"cjlst\", which=\"all\", evt_start=0, print_every=10000)  # event index: 52198\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_single_evt(t_matteo, 325159, 181, 259586791, fw=\"cjlst\", which=\"all\", evt_start=0, print_every=10000)  # event index: 52490\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_single_evt(t_elisa_353, 322430, 331, 543297179, fw=\"bbf\", which=\"all\", evt_start=0, print_every=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Difference between CJLST and BBF Analyzers:\n",
    "\n",
    "- Elisa has 432 unique 3P1F-only events (`elisa_3p1fonly_unique_ls`).\n",
    "- Of these, I scraped 236 events (`ntrsct_353evt_and_elisa3p1fonlyunique_ls`) and ran the UFHZZAnalyzer on them.\n",
    "\n",
    "Filippo suspects that CJLST does not require the Z1 leptons to be tight.\n",
    "\n",
    "- [ ] DO THIS LATER: Count how many of the 236 events have a Z1 lep which is not \"fully tight\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- DELETE BELOW. ---#\n",
    "from ROOT import TFile\n",
    "import numpy as np\n",
    "infile_elisa_unique_353 = \"/blue/avery/rosedj1/ZplusXpython/sidequests/rootfiles/elisa_unique_353events.root\"\n",
    "f_elisa_353 = TFile(infile_elisa_unique_353)\n",
    "t_elisa_353 = f_elisa_353.Get(\"Ana/passedEvents\")\n",
    "#--- DELETE ABOVE. ---#\n",
    "data = [len(evt.lep_pt) for evt in t_elisa_353]\n",
    "del t_elisa_353\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "bin_vals, bin_edges, _ = ax.hist(data, bins=range(0,12), align='left')\n",
    "ax.set_xlabel(r'Number of leptons per event')\n",
    "ax.set_ylabel(r'Number of events')\n",
    "ax.set_title(f'Analyzing 236/432 purely 3P1F events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cr_counts = Counter([tuple(sorted(v)) for v in elisa_3p1f_unique_evtid_dct.values()])\n",
    "# df = pd.DataFrame.from_dict(cr_counts, orient='index')\n",
    "# df.plot(kind='bar', legend=False, figsize=(12,9), grid=True, logy=False, fontsize=20, tick)\n",
    "\n",
    "cr_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tot_uniq = len(elisa_3p1f_unique_ls_tup)\n",
    "n_tot_cjlst = t_matteo.GetEntries()\n",
    "elisa_3p1f_unique_evtid_dct = {}\n",
    "\n",
    "for unique_evt_num, evt_id in enumerate(elisa_3p1f_unique_ls_tup[:1], 1):\n",
    "    if (unique_evt_num % 1) == 0:\n",
    "        print(f\"Searching for Elisa's unique event {unique_evt_num}/{n_tot_uniq}: {evt_id}\")\n",
    "    cr_ls = []\n",
    "    run   = evt_id[0]\n",
    "    lumi  = evt_id[1]\n",
    "    event = evt_id[2]\n",
    "    new_key = f\"{run} : {lumi} : {event}\"\n",
    "    for cjlst_evt_num, cjlst_evt in enumerate(t_matteo):\n",
    "        if (cjlst_evt_num % 10000) == 0:\n",
    "            print(f\"Scanning CJLST TTree for matching entry: {cjlst_evt_num}/{n_tot_cjlst}\")\n",
    "        if (run != cjlst_evt.RunNumber):\n",
    "            continue\n",
    "        if (lumi != cjlst_evt.LumiNumber):\n",
    "            continue\n",
    "        if (event != cjlst_evt.EventNumber):\n",
    "            continue\n",
    "        print(f\"EVENT FOUND! Entry number: {cjlst_evt_num}\")\n",
    "        cr_ls.extend([CjlstFlag(cjlst_evt.CRflag).name])\n",
    "    # cr_ls = [CjlstFlag(evt.CRflag).name for evt in t_matteo if (run == evt.RunNumber) and (lumi == evt.LumiNumber) and (event == evt.EventNumber)]\n",
    "    elisa_3p1f_unique_evtid_dct[new_key] = cr_ls\n",
    "pprint(elisa_3p1f_unique_evtid_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_id_ls_matteo = [(evt.RunNumber, evt.LumiNumber, evt.EventNumber,) for evt in t_matteo]\n",
    "len(evt_id_ls_matteo) - len(set(evt_id_ls_matteo))\n",
    "counter = Counter(evt_id_ls_matteo)\n",
    "# pprint(list(counter.values())[:5])\n",
    "dup_key_ls = [(k, ct) for k,ct in counter.items() if k == (315488, 152, 135937874,)]\n",
    "\n",
    "evt_id_tup = (315488, 152, 135937874, )\n",
    "counter[evt_id_tup]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find how many of CJLST RedBkg events contain exactly 4 leps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "#--- CJLST ---#\n",
    "###############\n",
    "n_tot = t_matteo.GetEntries()\n",
    "redbkg_CRs = [flag.name for flag in CjlstFlag]\n",
    "cr_flag_ls_cjlst = []\n",
    "\n",
    "print(\"Finding all events in CJLST file with 4 leps per event.\")\n",
    "for evt_num, evt in enumerate(t_matteo):\n",
    "    if (evt_num % 10000) == 0:\n",
    "        print(f\"Event {evt_num}/{n_tot}\")\n",
    "    n_reco_ele = evt.NRecoEle\n",
    "    n_reco_mu  = evt.NRecoMu\n",
    "    if (n_reco_ele + n_reco_mu) != 4:\n",
    "        continue\n",
    "    cr_flag_ls_cjlst.extend([evt.CRflag])\n",
    "# Count occurrence of each CR:\n",
    "print(f\"Number of events with 4 leps: {len(cr_flag_ls_cjlst)}\")\n",
    "cr_flag_cntr_cjlst = Counter(cr_flag_ls_cjlst)\n",
    "pprint([(CjlstFlag(k).name, ct) for k, ct in cr_flag_cntr_cjlst.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#--- BBF ---#\n",
    "#############\n",
    "n_tot = t_jake.GetEntries()\n",
    "redbkg_CRs = [flag.name for flag in CjlstFlag]\n",
    "cr_flag_ls_bbf = []\n",
    "evts_to_investigate = []\n",
    "\n",
    "print(\"Finding all events in BBF file with 4 leps per event.\")\n",
    "for evt_num, evt in enumerate(t_jake):\n",
    "    if (evt_num % 5000) == 0:\n",
    "        print(f\"Event {evt_num}/{n_tot}\")\n",
    "    if len(evt.lep_pt) != 4:\n",
    "        continue\n",
    "    cr_flag_ls_bbf.extend([get_control_region(evt)])\n",
    "\n",
    "    if sum(list(evt.lep_tightId)) >= 4:\n",
    "        evts_to_investigate.extend([evt_num])\n",
    "# Count occurrence of each CR:\n",
    "print(f\"Number of events with 4 leps: {len(cr_flag_ls_bbf)}\")\n",
    "cr_flag_cntr_bbf = Counter(cr_flag_ls_bbf)\n",
    "pprint([(k, ct) for k, ct in cr_flag_cntr_bbf.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What the heck? I've found events with `passedZXCRSelection == 1` but with exactly 4 tight leps...\n",
    "\n",
    "#### We must also keep in mind the RelIso!\n",
    "\n",
    "Let's investigate the originally-produced data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_muonEG2018 = \"/cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/MuonEG.root\"\n",
    "f_muonEG2018 = TFile(infile_muonEG2018)\n",
    "t_muonEG2018 = f_muonEG2018.Get(\"Ana/passedEvents\")\n",
    "t_muonEG2018.GetEntries()  # 5228705.\n",
    "t_muonEG2018.GetEntries(\"passedZXCRSelection==1\")  # 8363.\n",
    "t_muonEG2018.GetEntries(\"passedZXCRSelection==1 && Sum$(lep_tightId) == 4 && Length$(lep_pt) == 4\")  # 353.\n",
    "# Comparing per-element of a vector - Filippo suggests: &Lep_pt[0]\n",
    "\n",
    "# weird_tightId_ls = [] \n",
    "# for evt_num, evt in enumerate(t_muonEG2018):\n",
    "#     if () == 0: print(f\"\")\n",
    "#     if not evt.passedZXCRSelection: continue \n",
    "#     tightId_ls = list(evt.lep_tightId) \n",
    "#     if len(tightId_ls) != 4: continue \n",
    "#     if sum(tightId_ls) != 4: continue \n",
    "#     weird_tightId_ls.extend([evt_num]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many tight leptons are there per event?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ROOT import TFile, TCanvas, TPaveText, gStyle, gPad\n",
    "from Utils_ROOT.ROOT_classes import make_TH2F, normalize_TH2_per_column\n",
    "from Utils_ROOT.Printer import CanvasPrinter\n",
    "from Utils_Python.Plot_Styles_ROOT.tdrstyle_official import setTDRStyle, tdrGrid, fixOverlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_filippo_data2018 = TFile.Open(\"/cmsuf/data/store/user/t2/users/rosedj1/HiggsMassMeasurement/Samples/skim2L/Data/2018/fullstats/filippo/rootfiles/Data_2018_03Nov.root\")\n",
    "t_filippo_data2018 = f_filippo_data2018.Get(\"passedEvents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Filippo's 2018 Data to identify all 2PWF, 3PXF, 4PYF, 5PZF, etc. events.\n",
    "\n",
    "- [ ] Count all such events.\n",
    "- [ ] Make TH2 dists for all types.\n",
    "- [ ] Create new root file with new branches (is2P2F, is3P1F, is4P0F)\n",
    "   - [ ] Maybe use enums?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======> EVENT:0\n Run             = 315257\n Event           = 563224\n LumiSect        = 1\n nVtx            = 30\n nInt            = -1\n PV_x            = 0.0946384\n PV_y            = -0.0713265\n PV_z            = -5.62278\n BS_x            = 0.0968526\n BS_y            = -0.0701482\n BS_z            = -0.203083\n BS_xErr         = 1.74949e-06\n BS_yErr         = 1.80432e-06\n BS_zErr         = 0.0185527\n BeamWidth_x     = 0.000768446\n BeamWidth_y     = 0.000622493\n BeamWidth_xErr  = 5.93635e-06\n BeamWidth_yErr  = 5.93635e-06\n finalState      = -1\n passedFullSelection = 0\n passedZXCRSelection = 0\n genWeight       = 1\n k_ggZZ          = 1\n k_qqZZ_qcd_M    = 1\n k_qqZZ_ewk      = 1\n pileupWeight    = 1\n dataMCWeight    = 1\n eventWeight     = 1\n prefiringWeight = 1\n crossSection    = 1\n lep_d0BS        = (vector<float>*)0x559a63cc2630\n lep_d0PV        = (vector<float>*)0x559a63c4ac20\n lep_numberOfValidPixelHits = (vector<float>*)0x559a63c9b2b0\n lep_trackerLayersWithMeasurement = (vector<float>*)0x559a63cd7810\n vtxLep_BS_pt    = (vector<double>*)0x559a63cde6a0\n vtxLep_BS_pt_NoRoch = (vector<double>*)0x559a573a1fd0\n vtxLep_BS_ptError = (vector<double>*)0x559a573ad0e0\n vtxLep_BS_eta   = (vector<double>*)0x559a5735cc00\n vtxLep_BS_phi   = (vector<double>*)0x559a63c9ed50\n vtxLep_BS_mass  = (vector<double>*)0x559a63c17630\n vtxLep_BS_d0    = (vector<double>*)0x559a63c60930\n vtxLep_pt       = (vector<double>*)0x559a63ca9a60\n vtxLep_ptError  = (vector<double>*)0x559a57345ea0\n vtxLep_eta      = (vector<double>*)0x559a63c65fa0\n vtxLep_phi      = (vector<double>*)0x559a63cd9d70\n vtxLep_mass     = (vector<double>*)0x559a63d4cb10\n vtxLepFSR_BS_pt = (vector<double>*)0x559a573abd10\n vtxLepFSR_BS_eta = (vector<double>*)0x559a56e6ad20\n vtxLepFSR_BS_phi = (vector<double>*)0x559a573a3fe0\n vtxLepFSR_BS_mass = (vector<double>*)0x559a63c33a90\n vtxLepFSR_pt    = (vector<double>*)0x559a63d429e0\n vtxLepFSR_eta   = (vector<double>*)0x559a63c11430\n vtxLepFSR_phi   = (vector<double>*)0x559a63c2d0a0\n vtxLepFSR_mass  = (vector<double>*)0x559a63cc6130\n commonPV_x      = (vector<double>*)0x559a572ccb40\n commonPV_y      = (vector<double>*)0x559a573aa8b0\n commonPV_z      = (vector<double>*)0x559a63c97370\n commonBS_x      = (vector<double>*)0x559a63cf1000\n commonBS_y      = (vector<double>*)0x559a63c58fe0\n commonBS_z      = (vector<double>*)0x559a63cf06c0\n lep_pt_genFromReco = (vector<float>*)0x559a63c57990\n lep_id          = (vector<int>*)0x559a63d1cfb0\n lep_pt          = (vector<float>*)0x559a63cf1700\n lep_pterr       = (vector<float>*)0x559a63ccb8d0\n lep_eta         = (vector<float>*)0x559a63ccbff0\n lep_phi         = (vector<float>*)0x559a63ccc330\n lep_mass        = (vector<float>*)0x559a63d1b2e0\n lepFSR_pt       = (vector<float>*)0x559a573855b0\n lepFSR_eta      = (vector<float>*)0x559a53d613a0\n lepFSR_phi      = (vector<float>*)0x559a5410e2e0\n lepFSR_mass     = (vector<float>*)0x559a547c8db0\n lep_Hindex      = -1, \n                  -1, -1, -1\n lep_ecalDriven  = (vector<int>*)0x559a547816a0\n lep_tightId     = (vector<int>*)0x559a5410f3c0\n lep_Sip         = (vector<float>*)0x559a5452f700\n lep_RelIso      = (vector<float>*)0x559a547c9110\n lep_RelIsoNoFSR = (vector<float>*)0x559a5410ea60\n dataMC_VxBS     = (vector<float>*)0x559a53ee9dd0\n mass4l          = 0\n mass4lErr       = -999\n mass4lREFIT     = -999\n mass4lErrREFIT  = -999\n massZ1REFIT     = -999\n massZ2REFIT     = -999\n mass4l_vtx_BS   = -1\n mass4l_vtxFSR_BS = -1\n mass4lErr_vtx_BS = -999\n mass4lREFIT_vtx_BS = -999\n mass4lErrREFIT_vtx_BS = -999\n massZ1REFIT_vtx_BS = -999\n massZ2REFIT_vtx_BS = -999\n mass4l_vtx      = -1\n mass4l_vtxFSR   = -1\n mass4lErr_vtx   = -999\n mass4lREFIT_vtx = -999\n mass4lErrREFIT_vtx = -999\n massZ1          = 0\n massH_vtx_chi2_BS = 999\n massZ2          = 0\n met             = 21.9217\n D_bkg_kin       = 999\n D_bkg_kin_vtx_BS = 999\n D_bkg           = 999\n D_VBF           = 999\n"
     ]
    }
   ],
   "source": [
    "t_filippo_data2018.Show(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Particles import MyMuon, MyElectron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_valid_z1_candidate(lep1, lep2):\n",
    "    \"\"\"Return True if lep1 and lep2 form a valid Z1 candidate.\n",
    "    \n",
    "    NOTE:\n",
    "    - Leptons must be OSSF.\n",
    "    - 12 < m(ll, including FSR) < 120 GeV.\n",
    "\n",
    "    Args:\n",
    "        lep1 (MyMuon): Combined with lep2 to make Z cand.\n",
    "        lep2 (MyMuon): Combined with lep1 to make Z cand.\n",
    "    \"\"\"\n",
    "    # Check OSSF:\n",
    "    if lep1.charge == (-1 * lep2.charge):\n",
    "        # Check m(ll):\n",
    "        lorentz_lep1 = lep1.get_LorentzVector(kind=\"withFSR\")\n",
    "        lorentz_lep2 = lep2.get_LorentzVector(kind=\"withFSR\")\n",
    "        zmass = (lorentz_lep1 + lorentz_lep2).M()\n",
    "        if (12 < zmass) and (zmass < 120):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def pass_kinematics(lid, lpt, leta):\n",
    "    if abs(lid) == 11:\n",
    "        if lpt < 7:\n",
    "            return False\n",
    "        if abs(leta) > 2.5:\n",
    "            return False\n",
    "        # Electron passed selections.\n",
    "        return True\n",
    "    elif abs(lid) == 13:\n",
    "        if lpt < 5:\n",
    "            return False\n",
    "        if abs(leta) > 2.4:\n",
    "            return False\n",
    "        # Muon passed selections.\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_z1_candidates(lepFSR_pt, lepFSR_eta, lepFSR_phi, lepFSR_mass):\n",
    "\n",
    "    return z1_cand_ls\n",
    "\n",
    "n_tot = tree.GetEntries()\n",
    "for evt_num in range(n_tot):\n",
    "    tree.GetEntry(evt_num)\n",
    "\n",
    "    n_tot_leps = len(tree.lepFSR_pt)\n",
    "    lepFSR_pt_ls = list(tree.lepFSR_pt)\n",
    "    lepFSR_eta_ls = list(tree.lepFSR_eta)\n",
    "    lepFSR_phi_ls = list(tree.lepFSR_phi)\n",
    "    lepFSR_mass_ls = list(tree.lepFSR_mass)\n",
    "    lep_id_ls = list(tree.lep_id)\n",
    "    lep_tightId_ls = list(tree.lep_tightId)\n",
    "    # Loop over pairs of leptons to find Z1 candidates:\n",
    "    for this_ndx in range(n_tot_leps):\n",
    "        this_id = lep_id_ls[this_ndx]\n",
    "        this_pt = lepFSR_pt_ls[this_ndx]\n",
    "        this_eta = lepFSR_eta_ls[this_ndx]\n",
    "        # Every lepton must individually pass kinematic selections:\n",
    "        if not pass_kinematics(this_id, this_pt, this_eta):\n",
    "            continue\n",
    "        for that_ndx in range(this_ndx+1, n_tot_leps):\n",
    "            # Check all possible lepton combos:\n",
    "            that_id = lep_id_ls[that_ndx]\n",
    "            that_pt = lepFSR_pt_ls[that_ndx]\n",
    "            that_eta = lepFSR_eta_ls[that_ndx]\n",
    "            if not pass_kinematics(that_id, that_pt, that_eta):\n",
    "                continue\n",
    "            \n",
    "\n",
    "            \n",
    "             ? Need to check lepton kinematics (pT, eta, dxy, dz, SIP3D)\n",
    "            if make_valid_z1_candidate(lep1, lep2):\n",
    "                z_cand = \n",
    "                ? Add z_cand to list?\n",
    "\n",
    "    # All Z1 candidates found!\n",
    "            lep1 = list(tree.lep_id)\n",
    "\n",
    "\n",
    "\n",
    "            mylep_first = MyParticle()\n",
    "            mylep_second = MyParticle()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for pt_, eta_, phi_, mass_, id_, tightId_ in zip(\n",
    "        tree.lepFSR_pt,\n",
    "        tree.lepFSR_eta,\n",
    "        tree.lepFSR_phi,\n",
    "        tree.lepFSR_mass,\n",
    "        tree.lep_id,\n",
    "        tree.lep_tightId,\n",
    "        ):\n",
    "\n",
    "\n",
    "\n",
    "    my_lep_ls = \n",
    "    z1_cand_ls = get_all_z1_candidates()\n",
    "\n"
   ]
  }
 ]
}